const local_index = {"config": {"lang": ["en"], "min_search_length": 3, "prebuild_index": false, "separator": "[\\s\\-]+"}, "docs": [{"location": "index.html", "text": "Welcome to the Iristick SDK 1.3.2 \u00b6 Info The latest version of the SDK is available at https://developer.iristick.com/latest/ . if (document.location.href.startsWith(\"https://developer.iristick.com/latest/\")) { document.querySelector(\"div.admonition\").style.display = 'none'; } Welcome to the Iristick developer site. Iristick smart glasses are industrial smart glasses that connect to an Android smartphone, enhancing the phone's capabilities with additional display, cameras, microphones, speaker, and other sensors mounted on the headset. For more information about the smart glasses, please visit https://iristick.com/ . In contrast to standalone smart glasses, Iristick smart glasses are best thought of as smartphone accessories , i.e., they extend the phone's features rather than replacing them. Applications built for Iristick smart glasses run on the phone and may use both the features of the phone and of the connected Iristick smart glasses. Thanks to Android's open design, most smart glasses features are integrated with the operating system. For example, when smart glasses are connected, audio is automatically played on the headset speaker. The headset display mirrors the phone's display. The headset touchpad allows to navigate through the widgets on the screen. When the phone is burried away in a pocket or a pouch, the user interface is optimized for the heads-up display. Hence, simple applications might work without any modifications with the Iristick smart glasses. Using this SDK allows to further optimize the user experience on the Iristick smart glasses. Due to technical constraints of the Android operating system, some features, such as the cameras or the inertial sensors, are not natively integrated. The use of this SDK is required to get access to those features. Read the Getting Started guide for more information. The complete SDK, including libraries, APKs, example code, and this documentation can be downloaded as one package through the following link. Download SDK package", "title": "Home"}, {"location": "index.html#welcome-to-the-iristick-sdk-132", "text": "Info The latest version of the SDK is available at https://developer.iristick.com/latest/ . if (document.location.href.startsWith(\"https://developer.iristick.com/latest/\")) { document.querySelector(\"div.admonition\").style.display = 'none'; } Welcome to the Iristick developer site. Iristick smart glasses are industrial smart glasses that connect to an Android smartphone, enhancing the phone's capabilities with additional display, cameras, microphones, speaker, and other sensors mounted on the headset. For more information about the smart glasses, please visit https://iristick.com/ . In contrast to standalone smart glasses, Iristick smart glasses are best thought of as smartphone accessories , i.e., they extend the phone's features rather than replacing them. Applications built for Iristick smart glasses run on the phone and may use both the features of the phone and of the connected Iristick smart glasses. Thanks to Android's open design, most smart glasses features are integrated with the operating system. For example, when smart glasses are connected, audio is automatically played on the headset speaker. The headset display mirrors the phone's display. The headset touchpad allows to navigate through the widgets on the screen. When the phone is burried away in a pocket or a pouch, the user interface is optimized for the heads-up display. Hence, simple applications might work without any modifications with the Iristick smart glasses. Using this SDK allows to further optimize the user experience on the Iristick smart glasses. Due to technical constraints of the Android operating system, some features, such as the cameras or the inertial sensors, are not natively integrated. The use of this SDK is required to get access to those features. Read the Getting Started guide for more information. The complete SDK, including libraries, APKs, example code, and this documentation can be downloaded as one package through the following link. Download SDK package", "title": "Welcome to the Iristick SDK 1.3.2"}, {"location": "getting-started/index.html", "text": "Getting started \u00b6 This guide will help you get started on the development of apps targeting Iristick smart glasses. The guide consists of the following steps: During phone setup , we will cover the installation of the Iristick Services app on the Android phone. The app must be installed on all phones that are used with Iristick smart glasses, including on end user devices. In the development environment step, we will set up the development environment to get the Iristick libraries and easily debug code. Finally, in Using the API , we will build a basic app connecting to the Iristick Services to make use of the Iristick smart glasses.", "title": "Overview"}, {"location": "getting-started/index.html#getting-started", "text": "This guide will help you get started on the development of apps targeting Iristick smart glasses. The guide consists of the following steps: During phone setup , we will cover the installation of the Iristick Services app on the Android phone. The app must be installed on all phones that are used with Iristick smart glasses, including on end user devices. In the development environment step, we will set up the development environment to get the Iristick libraries and easily debug code. Finally, in Using the API , we will build a basic app connecting to the Iristick Services to make use of the Iristick smart glasses.", "title": "Getting started"}, {"location": "getting-started/development-environment.html", "text": "Setting up the development environment \u00b6 Applications targeting Iristick smart glasses run on a standard Android smartphone, and are thus developed like normal mobile applications. For more information, see the Android Developers site . Note Because the applications targeting Iristick smart glasses run on the smartphone, the Glass templates should not be used to set up an Android Studio project. Adding Iristick libraries to an Android Studio Project \u00b6 To make use of all the features of Iristick smart glasses through the API described further in this documentation, the Iristick libraries must be added to the dependencies of the project. First, the Iristick repository should be added to the project's root build.gradle file. The allprojects section should look like this: allprojects { repositories { google () jcenter () ivy { url 'https://developer.iristick.com/repo' } } } Alternatively, you can download and extract the SDK ZIP package . The libs folder contains the libraries structured as an Ivy repository. To use the extracted folder, the allprojects section should look like: allprojects { repositories { google () jcenter () ivy { url 'file:///path/to/sdk/libs' } } } The Iristick core library can then be added as a dependency to the build.gradle file of the app module: dependencies { implementation 'com.iristick.smartglass:core:1.3.2' implementation 'com.iristick.smartglass:support:1.3.2' } Debugging on a phone connected to Iristick smart glasses \u00b6 Debugging an application targeting Iristick smart glasses cannot be done by connecting the smartphone to the developer computer through USB, as the USB port is already used by the smart glasses connection. Instead, the Android Debug Bridge (ADB) can be used over Wifi. Connect the smartphone to be debugged to the developer computer with a USB cable and enable network access by running adb -d tcpip 5555 Disconnect the smartphone from the developer computer and run (replace 192.168.0.10 with the IP address of the smartphone): adb connect 192.168.0.10:5555 ADB can now be used as usual, including debugging with Android Studio. Mirroring the content of the display \u00b6 The content of the headset display can be mirrored on the desktop. To do so, open the Iristick Services settings and check Web console under Developer settings . Next, on a desktop browser in the same network as the smartphone, browse to the URL given on the settings screen. Note The developer console is only accessible when a headset is connected.", "title": "Development environment"}, {"location": "getting-started/development-environment.html#setting-up-the-development-environment", "text": "Applications targeting Iristick smart glasses run on a standard Android smartphone, and are thus developed like normal mobile applications. For more information, see the Android Developers site . Note Because the applications targeting Iristick smart glasses run on the smartphone, the Glass templates should not be used to set up an Android Studio project.", "title": "Setting up the development environment"}, {"location": "getting-started/development-environment.html#adding-iristick-libraries-to-an-android-studio-project", "text": "To make use of all the features of Iristick smart glasses through the API described further in this documentation, the Iristick libraries must be added to the dependencies of the project. First, the Iristick repository should be added to the project's root build.gradle file. The allprojects section should look like this: allprojects { repositories { google () jcenter () ivy { url 'https://developer.iristick.com/repo' } } } Alternatively, you can download and extract the SDK ZIP package . The libs folder contains the libraries structured as an Ivy repository. To use the extracted folder, the allprojects section should look like: allprojects { repositories { google () jcenter () ivy { url 'file:///path/to/sdk/libs' } } } The Iristick core library can then be added as a dependency to the build.gradle file of the app module: dependencies { implementation 'com.iristick.smartglass:core:1.3.2' implementation 'com.iristick.smartglass:support:1.3.2' }", "title": "Adding Iristick libraries to an Android Studio Project"}, {"location": "getting-started/development-environment.html#debugging-on-a-phone-connected-to-iristick-smart-glasses", "text": "Debugging an application targeting Iristick smart glasses cannot be done by connecting the smartphone to the developer computer through USB, as the USB port is already used by the smart glasses connection. Instead, the Android Debug Bridge (ADB) can be used over Wifi. Connect the smartphone to be debugged to the developer computer with a USB cable and enable network access by running adb -d tcpip 5555 Disconnect the smartphone from the developer computer and run (replace 192.168.0.10 with the IP address of the smartphone): adb connect 192.168.0.10:5555 ADB can now be used as usual, including debugging with Android Studio.", "title": "Debugging on a phone connected to Iristick smart glasses"}, {"location": "getting-started/development-environment.html#mirroring-the-content-of-the-display", "text": "The content of the headset display can be mirrored on the desktop. To do so, open the Iristick Services settings and check Web console under Developer settings . Next, on a desktop browser in the same network as the smartphone, browse to the URL given on the settings screen. Note The developer console is only accessible when a headset is connected.", "title": "Mirroring the content of the display"}, {"location": "getting-started/phone-setup.html", "text": "Connecting a phone to Iristick smart glasses \u00b6 Minimum requirements of the phone \u00b6 In order to use Iristick smart glasses with a smartphone, the smartphone must comply with the following minimum requirements: Android 7 operating system or later; Android 8 or later is strongly recommended due to important bug fixes in the display subsystem USB Type-C connector USB Host functionality Install Iristick Services \u00b6 The Iristick Services app is an Android application that has to be installed on all smartphones that are used together with Iristick smart glasses. The app handles all interaction with the smart glasses hardware and provides the implementation of the Iristick API described in this documentation. There are three ways of installing the Iristick Services app: manually , through Google Play , or through F-Droid . Manually \u00b6 The APK of Iristick Services can be downloaded with the following link: https://apk.iristick.com/release/IristickServices-1.3.2.apk The APK is also provided in the SDK ZIP package . Through Google Play \u00b6 The Iristick Services app is available on the Google Play Store . Through F-Droid \u00b6 F-Droid is an open-source application store that provides an alternative to the Google Play Store. In contrast to the latter, it allows the use of external private software repositories, like the one provided by Iristick, and does not require a Google account. Note On Android 7, the Android device must first allow the installation of software outside of the Google Play Store. Go to the System Preferences, in the Security category, enable Unknown sources . On Android 8, the operating system will ask to grant individual applications (the browser and F-Droid) the right to install third-party applications. Download and install F-Droid from https://f-droid.org/ . After installation, launch F-Droid and wait for its repositories to be synchronized. Go to the Settings tab, open the Repositories settings, and click on the + button in the toolbar. Enter the following repository address: https://apk.iristick.com/release Leave the Fingerprint field blank and click on Add . Wait again for F-Droid to synchronize. If desired, the standard F-Droid repository can be disabled. All Iristick applications are available in the Iristick category. Connect to Iristick smart glasses \u00b6 Connect the pocket unit to the Android phone with the USB cable, and the glasses to the pocket unit with the coax cable. Android may ask to grant permission to Iristick Services to use the USB device. Tip To avoid showing the USB permission dialog in the future, make sure to check Use by default for this USB device . Android will remember your choice for this specific pocket unit. If you use another pocket unit, you will get the dialog again. A notification saying Iristick headset connected will appear. If you get a notification with Synchronizing firmware instead, do not detach the Iristick devices until synchronization is done. After a few minutes, the Iristick headset connected notification should appear. On first use, the Iristick Services will ask for some permissions. Tap on the Permissions required notification and grant all permissions to make full use of the Iristick smart glasses. You may want to increase the phone's display size to improve readability on the heads-up display. A shortcut to the display settings are provided in the Iristick Services settings. Optional: try out the examples app \u00b6 The APK of the example code is included in the SDK ZIP package. It is also available on the Google Play Store and in the F-Droid repository. The examples app can be used to try out various functionalities of the Iristick smart glasses.", "title": "Phone setup"}, {"location": "getting-started/phone-setup.html#connecting-a-phone-to-iristick-smart-glasses", "text": "", "title": "Connecting a phone to Iristick smart glasses"}, {"location": "getting-started/phone-setup.html#minimum-requirements-of-the-phone", "text": "In order to use Iristick smart glasses with a smartphone, the smartphone must comply with the following minimum requirements: Android 7 operating system or later; Android 8 or later is strongly recommended due to important bug fixes in the display subsystem USB Type-C connector USB Host functionality", "title": "Minimum requirements of the phone"}, {"location": "getting-started/phone-setup.html#install-iristick-services", "text": "The Iristick Services app is an Android application that has to be installed on all smartphones that are used together with Iristick smart glasses. The app handles all interaction with the smart glasses hardware and provides the implementation of the Iristick API described in this documentation. There are three ways of installing the Iristick Services app: manually , through Google Play , or through F-Droid .", "title": "Install Iristick Services"}, {"location": "getting-started/phone-setup.html#manually", "text": "The APK of Iristick Services can be downloaded with the following link: https://apk.iristick.com/release/IristickServices-1.3.2.apk The APK is also provided in the SDK ZIP package .", "title": "Manually"}, {"location": "getting-started/phone-setup.html#through-google-play", "text": "The Iristick Services app is available on the Google Play Store .", "title": "Through Google Play"}, {"location": "getting-started/phone-setup.html#through-f-droid", "text": "F-Droid is an open-source application store that provides an alternative to the Google Play Store. In contrast to the latter, it allows the use of external private software repositories, like the one provided by Iristick, and does not require a Google account. Note On Android 7, the Android device must first allow the installation of software outside of the Google Play Store. Go to the System Preferences, in the Security category, enable Unknown sources . On Android 8, the operating system will ask to grant individual applications (the browser and F-Droid) the right to install third-party applications. Download and install F-Droid from https://f-droid.org/ . After installation, launch F-Droid and wait for its repositories to be synchronized. Go to the Settings tab, open the Repositories settings, and click on the + button in the toolbar. Enter the following repository address: https://apk.iristick.com/release Leave the Fingerprint field blank and click on Add . Wait again for F-Droid to synchronize. If desired, the standard F-Droid repository can be disabled. All Iristick applications are available in the Iristick category.", "title": "Through F-Droid"}, {"location": "getting-started/phone-setup.html#connect-to-iristick-smart-glasses", "text": "Connect the pocket unit to the Android phone with the USB cable, and the glasses to the pocket unit with the coax cable. Android may ask to grant permission to Iristick Services to use the USB device. Tip To avoid showing the USB permission dialog in the future, make sure to check Use by default for this USB device . Android will remember your choice for this specific pocket unit. If you use another pocket unit, you will get the dialog again. A notification saying Iristick headset connected will appear. If you get a notification with Synchronizing firmware instead, do not detach the Iristick devices until synchronization is done. After a few minutes, the Iristick headset connected notification should appear. On first use, the Iristick Services will ask for some permissions. Tap on the Permissions required notification and grant all permissions to make full use of the Iristick smart glasses. You may want to increase the phone's display size to improve readability on the heads-up display. A shortcut to the display settings are provided in the Iristick Services settings.", "title": "Connect to Iristick smart glasses"}, {"location": "getting-started/phone-setup.html#optional-try-out-the-examples-app", "text": "The APK of the example code is included in the SDK ZIP package. It is also available on the Google Play Store and in the F-Droid repository. The examples app can be used to try out various functionalities of the Iristick smart glasses.", "title": "Optional: try out the examples app"}, {"location": "getting-started/using-api.html", "text": "Developing with the SDK \u00b6 Two libraries are included in the SDK: the core library and the support library. The core library provides low-level access to the Iristick smart glasses. The support library is a thin layer on top of the core library providing easy management of Iristick smart glasses and reducing boilerplate code. Hence, it is recommended to use the support library in most cases. This page will detail the use of the support library. Adding the support library to a project \u00b6 First, add the following dependencies to your project: dependencies { implementation 'com.iristick.smartglass:core:1.3.2' implementation 'com.iristick.smartglass:support:1.3.2' } Next, create an Android Application subclass, and add the following code in the onCreate() method. If you already have an Application subclass, just add the IristickApp.init call in your onCreate() method. It is important that the init method has been called before any other use of the libraries. public class MyApplication extends Application { @Override public void onCreate () { super . onCreate (); IristickApp . init ( this ); } } Tip The behavior of the SDK can be customized by passing an IristickConfiguration object as second parameter to IristickApp.init . Make sure the application is registered in the manifest by setting the android:name attribute of the <application> tag to the name of your Application subclass. At last, add the following method to all activities in your project. The easiest way to do so is to create an abstract base class extending Activity and let all your project's activities inherit from it. @Override protected void attachBaseContext ( Context newBase ) { super . attachBaseContext ( IristickApp . wrapContext ( newBase )); } Designing apps for the Iristick smart glasses \u00b6 By default, the heads-up display on the Iristick smart glasses mirrors the content of the phone screen. When the user is interacting with the smart glasses through the touchpad or through voice, the display is adapted to optimize for the heads-up display: Landscape orientation is forced, The notouch variants of resources are used (if available), The phone touchscreen is locked. The above optimizations are also applied when the phone is buried away in a pocket or a pouch. To disable this behavior, uncheck Detect Pouch in the Iristick Services settings. To provide an alternative layout to be used when the smartphone screen is not visible, add a new resource in Android Studio. In the New Resource File dialog, select the Touch Screen qualifier with value No Touch . Whenever a headset is attached or detached, or when the interaction mode changes, your activities will be recreated, as if a configuration change has occurred. You can override this behavior in the IristickConfiguration object passed to IristickApp.init() . Designing custom UI for the heads-up display \u00b6 If cloning the phone display on the heads-up display is not desired, you can also provide a fully custom UI for the heads-up display that is independent of the phone UI. Subclass the HudPresentation class to provide the custom UI to show on the heads-up display. Next, implement the HudActivity interface on each activity for which you want to provide custom UI, and provide an instance of your HudPresentation subclass. class MyHud extends HudPresentation { private TextView mText ; MyHud ( @NonNull Context outerContext , @NonNull Display display ) { super ( outerContext , display ); } @Override protected void onCreate ( @Nullable Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ); /* Set layout. */ setContentView ( R . layout . my_hud ); /* Get widgets defined in the layout. */ mText = findViewById ( R . id . text ); } public boolean onTouchEvent ( @NonNull TouchEvent event ) { /* Handle incoming touch events */ switch ( event . getGestureCode ()) { case TouchEvent . GESTURE_TAP : mText . setText ( \"Tap!\" ); return true ; default : return false ; } } } Accessing smart glasses features \u00b6 To get access to all the features on the Iristick smart glasses, call IristickApp.getHeadset() . This will return a Headset object or null if no smart glasses are currently connected. The Headset object represents the attached smart glasses and is the entry point to all functionality. When a headset gets attached or detached, the activity will be recreated so that you can act upon the change. If you need access to the attached smart glasses outside of an activity, you can register a listener with IristickApp.registerConnectionListener . Microphones and speaker are fully integrated in the Android platform and are automatically used whenever Iristick smart glasses are attached. Use the standard Android audio APIs . To directly draw on the display , bypassing the integration described above, either request a Display object through Headset.openDisplay() , or a Surface object through Headset.openDisplaySurface() . Using the former method, any Android UI elements can be drawn by subclassing the Presentation class. Using the latter method, a frame can be drawn manually by calling Surface.lockCanvas() . Cameras are accessible via the camera package of this SDK, which provides an API similar to the android.hardware.camera2 API. Touchpad events are received by registering an implementation of TouchEvent.Callback . Sensors (such as accelerometer, gyroscope and magnetometer) can be queried with Headset.getSensorList(type) . Register a listener to enable a sensor and receive measurements. Voice commands are discovered from the properties of clickable elements shown on screen. This behavior can be customized and additional commands can be provided through the API.", "title": "Using the API"}, {"location": "getting-started/using-api.html#developing-with-the-sdk", "text": "Two libraries are included in the SDK: the core library and the support library. The core library provides low-level access to the Iristick smart glasses. The support library is a thin layer on top of the core library providing easy management of Iristick smart glasses and reducing boilerplate code. Hence, it is recommended to use the support library in most cases. This page will detail the use of the support library.", "title": "Developing with the SDK"}, {"location": "getting-started/using-api.html#adding-the-support-library-to-a-project", "text": "First, add the following dependencies to your project: dependencies { implementation 'com.iristick.smartglass:core:1.3.2' implementation 'com.iristick.smartglass:support:1.3.2' } Next, create an Android Application subclass, and add the following code in the onCreate() method. If you already have an Application subclass, just add the IristickApp.init call in your onCreate() method. It is important that the init method has been called before any other use of the libraries. public class MyApplication extends Application { @Override public void onCreate () { super . onCreate (); IristickApp . init ( this ); } } Tip The behavior of the SDK can be customized by passing an IristickConfiguration object as second parameter to IristickApp.init . Make sure the application is registered in the manifest by setting the android:name attribute of the <application> tag to the name of your Application subclass. At last, add the following method to all activities in your project. The easiest way to do so is to create an abstract base class extending Activity and let all your project's activities inherit from it. @Override protected void attachBaseContext ( Context newBase ) { super . attachBaseContext ( IristickApp . wrapContext ( newBase )); }", "title": "Adding the support library to a project"}, {"location": "getting-started/using-api.html#designing-apps-for-the-iristick-smart-glasses", "text": "By default, the heads-up display on the Iristick smart glasses mirrors the content of the phone screen. When the user is interacting with the smart glasses through the touchpad or through voice, the display is adapted to optimize for the heads-up display: Landscape orientation is forced, The notouch variants of resources are used (if available), The phone touchscreen is locked. The above optimizations are also applied when the phone is buried away in a pocket or a pouch. To disable this behavior, uncheck Detect Pouch in the Iristick Services settings. To provide an alternative layout to be used when the smartphone screen is not visible, add a new resource in Android Studio. In the New Resource File dialog, select the Touch Screen qualifier with value No Touch . Whenever a headset is attached or detached, or when the interaction mode changes, your activities will be recreated, as if a configuration change has occurred. You can override this behavior in the IristickConfiguration object passed to IristickApp.init() .", "title": "Designing apps for the Iristick smart glasses"}, {"location": "getting-started/using-api.html#designing-custom-ui-for-the-heads-up-display", "text": "If cloning the phone display on the heads-up display is not desired, you can also provide a fully custom UI for the heads-up display that is independent of the phone UI. Subclass the HudPresentation class to provide the custom UI to show on the heads-up display. Next, implement the HudActivity interface on each activity for which you want to provide custom UI, and provide an instance of your HudPresentation subclass. class MyHud extends HudPresentation { private TextView mText ; MyHud ( @NonNull Context outerContext , @NonNull Display display ) { super ( outerContext , display ); } @Override protected void onCreate ( @Nullable Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ); /* Set layout. */ setContentView ( R . layout . my_hud ); /* Get widgets defined in the layout. */ mText = findViewById ( R . id . text ); } public boolean onTouchEvent ( @NonNull TouchEvent event ) { /* Handle incoming touch events */ switch ( event . getGestureCode ()) { case TouchEvent . GESTURE_TAP : mText . setText ( \"Tap!\" ); return true ; default : return false ; } } }", "title": "Designing custom UI for the heads-up display"}, {"location": "getting-started/using-api.html#accessing-smart-glasses-features", "text": "To get access to all the features on the Iristick smart glasses, call IristickApp.getHeadset() . This will return a Headset object or null if no smart glasses are currently connected. The Headset object represents the attached smart glasses and is the entry point to all functionality. When a headset gets attached or detached, the activity will be recreated so that you can act upon the change. If you need access to the attached smart glasses outside of an activity, you can register a listener with IristickApp.registerConnectionListener . Microphones and speaker are fully integrated in the Android platform and are automatically used whenever Iristick smart glasses are attached. Use the standard Android audio APIs . To directly draw on the display , bypassing the integration described above, either request a Display object through Headset.openDisplay() , or a Surface object through Headset.openDisplaySurface() . Using the former method, any Android UI elements can be drawn by subclassing the Presentation class. Using the latter method, a frame can be drawn manually by calling Surface.lockCanvas() . Cameras are accessible via the camera package of this SDK, which provides an API similar to the android.hardware.camera2 API. Touchpad events are received by registering an implementation of TouchEvent.Callback . Sensors (such as accelerometer, gyroscope and magnetometer) can be queried with Headset.getSensorList(type) . Register a listener to enable a sensor and receive measurements. Voice commands are discovered from the properties of clickable elements shown on screen. This behavior can be customized and additional commands can be provided through the API.", "title": "Accessing smart glasses features"}, {"location": "guides/barcode.html", "text": "Barcode scanning \u00b6 Barcode scanning capabilities depend on the Iristick smart glasses model. The following table summarizes the differences: Feature G1 / G2 G1 PRO / G2 PRO / H1 Scan with center camera \u2713 \u2713 Scan with zoom camera \u2713 \u2713 Select barcode to scan with laser \u2713 Scan multiple barcodes \u2713 Handle rotated barcodes \u2713 Advanced barcode formats \u2713 Enhanced performance \u2713 There are two ways to scan barcodes using the Iristick SDK. If you occasionally require your user to scan a single barcode, you can use the barcode scanning intent. If you have heavier barcode scanning flow, you can use the barcode scanning API. Example code The Barcode scanner example provided in the SDK package show how to use both the barcode scanning intent to scan a single barcode and the barcode scanning API to continuously scan for barcodes overlaying the results on top of the camera preview. Using the barcode scanning intent \u00b6 The easiest way to scan a barcode is to launch an intent with action ACTION_SCAN_BARCODE . The Iristick Services will then show its barcode scanning UI, asking the user to point the laser to the barcode to scan. Once the user's head is kept steady, the zoom camera will be used, if available, at different zoom levels to scan for the barcode. Once found, control is returned to your application. During the process, the user can cancel the operation by swiping down on the touchpad, saying go backwards , or tapping on the Android back key. The list of barcode formats that have to be recognized can optionally be set through the EXTRA_BARCODE_SCAN_FORMATS intent extra. If not provided, a subset of most common barcode formats is chosen. For better performance, try to enable as few formats as needed. public class MyActivity extends Activity { private static final int REQUEST_CODE = 0 ; // ... public void scanBarcode () { Intent intent = new Intent ( Intents . ACTION_SCAN_BARCODE ); intent . putExtra ( Intents . EXTRA_BARCODE_SCAN_FORMATS , \"QR_CODE\" ); // optional startActivityForResult ( intent , REQUEST_CODE ); } protected void onActivityResult ( int requestCode , int resultCode , @Nullable Intent data ) { super . onActivityResult ( requestCode , resultCode , data ); if ( requestCode == REQUEST_CODE ) { switch ( resultCode ) { case Intents . RESULT_OK : String text = data . getStringExtra ( Intents . EXTRA_BARCODE_RESULT ); String format = data . getStringExtra ( Intents . EXTRA_BARCODE_FORMAT ); /* The barcode was successfully scanned: * do something with the result. */ break ; case Intents . RESULT_CANCELLED : /* The user cancelled the operation. */ break ; default : /* An error occured. */ } } } } Using the barcode scanning API \u00b6 For more advanced barcode scanning workflows the barcode scanning extensions to the camera API can be used. Please read the camera API guide first for an introduction to the camera API. As with all camera capabilities, barcode scanning capabilities can be queried through the CameraCharacteristics object describing a camera. The following keys concern barcode scanning: POSTPROCESS_MAXIMUM_BARCODE_COUNT , POSTPROCESS_AVAILABLE_BARCODE_FORMATS . To enable barcode scanning, build capture requests with the TEMPLATE_BARCODE template. You can optionally set some CaptureRequest keys to configure the scanning process. CaptureRequest createCaptureRequest ( CameraDevice camera ) { /* Create the builder with the BARCODE template. */ CaptureRequest . Builder builder = camera . createCaptureRequest ( CameraDevice . TEMPLATE_BARCODE ); /* Add the preview surface(s) */ builder . addTarget ( mPreviewSurface ); /* Optional: set number of barcodes to scan * (defaults to max). */ builder . set ( CaptureRequest . POSTPROCESS_BARCODE_COUNT , 1 ); /* Optional: set barcode formats to recognize * (defaults to a common subset).*/ builder . set ( CaptureRequest . POSTPROCESS_BARCODE_FORMATS , new String [] { CaptureRequest . QR_CODE }); /* Build the capture request. */ return builder . build (); } The capture requests can then be submitted, preferably as repeating requests. Be sure to provide a capture listener to be notified of recognized barcodes. The capture listener must extend the CaptureListener2 abstract class. Barcode scanning results are only available in the onPostProcessCompleted callback. class MyCaptureListener extends CaptureListener2 { @Override public void onPostProcessCompleted ( @NonNull CaptureSession session , @NonNull CaptureRequest request , @NonNull CaptureResult result ) { Barcode [] barcodes = result . get ( CaptureResult . POSTPROCESS_BARCODES ); if ( barcodes != null && barcodes . length > 0 ) { /* Do something with the recognized barcodes. */ } } }", "title": "Barcode scanning"}, {"location": "guides/barcode.html#barcode-scanning", "text": "Barcode scanning capabilities depend on the Iristick smart glasses model. The following table summarizes the differences: Feature G1 / G2 G1 PRO / G2 PRO / H1 Scan with center camera \u2713 \u2713 Scan with zoom camera \u2713 \u2713 Select barcode to scan with laser \u2713 Scan multiple barcodes \u2713 Handle rotated barcodes \u2713 Advanced barcode formats \u2713 Enhanced performance \u2713 There are two ways to scan barcodes using the Iristick SDK. If you occasionally require your user to scan a single barcode, you can use the barcode scanning intent. If you have heavier barcode scanning flow, you can use the barcode scanning API. Example code The Barcode scanner example provided in the SDK package show how to use both the barcode scanning intent to scan a single barcode and the barcode scanning API to continuously scan for barcodes overlaying the results on top of the camera preview.", "title": "Barcode scanning"}, {"location": "guides/barcode.html#using-the-barcode-scanning-intent", "text": "The easiest way to scan a barcode is to launch an intent with action ACTION_SCAN_BARCODE . The Iristick Services will then show its barcode scanning UI, asking the user to point the laser to the barcode to scan. Once the user's head is kept steady, the zoom camera will be used, if available, at different zoom levels to scan for the barcode. Once found, control is returned to your application. During the process, the user can cancel the operation by swiping down on the touchpad, saying go backwards , or tapping on the Android back key. The list of barcode formats that have to be recognized can optionally be set through the EXTRA_BARCODE_SCAN_FORMATS intent extra. If not provided, a subset of most common barcode formats is chosen. For better performance, try to enable as few formats as needed. public class MyActivity extends Activity { private static final int REQUEST_CODE = 0 ; // ... public void scanBarcode () { Intent intent = new Intent ( Intents . ACTION_SCAN_BARCODE ); intent . putExtra ( Intents . EXTRA_BARCODE_SCAN_FORMATS , \"QR_CODE\" ); // optional startActivityForResult ( intent , REQUEST_CODE ); } protected void onActivityResult ( int requestCode , int resultCode , @Nullable Intent data ) { super . onActivityResult ( requestCode , resultCode , data ); if ( requestCode == REQUEST_CODE ) { switch ( resultCode ) { case Intents . RESULT_OK : String text = data . getStringExtra ( Intents . EXTRA_BARCODE_RESULT ); String format = data . getStringExtra ( Intents . EXTRA_BARCODE_FORMAT ); /* The barcode was successfully scanned: * do something with the result. */ break ; case Intents . RESULT_CANCELLED : /* The user cancelled the operation. */ break ; default : /* An error occured. */ } } } }", "title": "Using the barcode scanning intent"}, {"location": "guides/barcode.html#using-the-barcode-scanning-api", "text": "For more advanced barcode scanning workflows the barcode scanning extensions to the camera API can be used. Please read the camera API guide first for an introduction to the camera API. As with all camera capabilities, barcode scanning capabilities can be queried through the CameraCharacteristics object describing a camera. The following keys concern barcode scanning: POSTPROCESS_MAXIMUM_BARCODE_COUNT , POSTPROCESS_AVAILABLE_BARCODE_FORMATS . To enable barcode scanning, build capture requests with the TEMPLATE_BARCODE template. You can optionally set some CaptureRequest keys to configure the scanning process. CaptureRequest createCaptureRequest ( CameraDevice camera ) { /* Create the builder with the BARCODE template. */ CaptureRequest . Builder builder = camera . createCaptureRequest ( CameraDevice . TEMPLATE_BARCODE ); /* Add the preview surface(s) */ builder . addTarget ( mPreviewSurface ); /* Optional: set number of barcodes to scan * (defaults to max). */ builder . set ( CaptureRequest . POSTPROCESS_BARCODE_COUNT , 1 ); /* Optional: set barcode formats to recognize * (defaults to a common subset).*/ builder . set ( CaptureRequest . POSTPROCESS_BARCODE_FORMATS , new String [] { CaptureRequest . QR_CODE }); /* Build the capture request. */ return builder . build (); } The capture requests can then be submitted, preferably as repeating requests. Be sure to provide a capture listener to be notified of recognized barcodes. The capture listener must extend the CaptureListener2 abstract class. Barcode scanning results are only available in the onPostProcessCompleted callback. class MyCaptureListener extends CaptureListener2 { @Override public void onPostProcessCompleted ( @NonNull CaptureSession session , @NonNull CaptureRequest request , @NonNull CaptureResult result ) { Barcode [] barcodes = result . get ( CaptureResult . POSTPROCESS_BARCODES ); if ( barcodes != null && barcodes . length > 0 ) { /* Do something with the recognized barcodes. */ } } }", "title": "Using the barcode scanning API"}, {"location": "guides/cameras.html", "text": "Cameras \u00b6 The cameras on Iristick smart glasses are accessible only through the camera package . This package contains a set of classes and interfaces for opening camera devices , starting capture sessions and capturing frames with capture requests . This package is loosely modeled after the standard Android camera2 API. Example code The Camera Example provided in the SDK package shows how to use the Camera API. It shows a preview of both cameras on the display. The example shows how to adjust zoom and offset, and how to trigger auto-focus. Querying cameras \u00b6 Every camera device has a unique identifier. You can find the identifier of a camera with the findCamera() method of a Headset object, providing the desired type of camera. @Override public void onHeadsetConnected ( @NonNull Headset headset ) { String center = headset . findCamera ( CameraCharacteristics . TYPE_WIDE_ANGLE ); if ( center != null ) { // This headset has a wide-angle center camera. // Do something with it. } String zoom = headset . findCamera ( CameraCharacteristics . TYPE_ZOOM ); if ( zoom != null ) { // This headset has a zoom camera. // Do something with it. } } Alternatively, you can get a list of all available camera devices with the getCameraIdList() method of a Headset object. With an identifier, you can query the properties and capabilities of the corresponding camera with getCameraCharacteristics() . /** * Test if the camera device identified by cameraId supports 720p streaming. */ boolean supportsHD ( @NonNull Headset headset , @NonNull String cameraId ) { /* Get the characteristics for this specific camera. */ CameraCharacteristics characteristics = headset . getCameraCharacteristics ( cameraId ); /* Query the supported stream mapping. */ StreamConfigurationMap mapping = characteristics . get ( CameraCharacteristics . SCALER_STREAM_CONFIGURATION_MAP ) /* Test if 720p is in the list of supported sizes. */ for ( Point size : mapping . getSizes ()) { if ( size . x == 1280 && size . y == 720 ) return true ; } return false ; } Opening a camera \u00b6 The camera device is opened asynchronously with a call to openCamera() , supplying the identifier of the camera and an implementation of CameraDevice.Listener . The listener's onOpened method will be called when the camera is successfully opened. Important Opening a camera device requires the CAMERA permission. You can close the camera device with its close() method. This will close the active capture session. When another app has already opened a camera device, that app will be disconnected from the camera device and must reopen it in order to capture images again. @Override public void onHeadsetConnected ( @NonNull Headset headset ) { /* Open wide-angle center camera. */ String cameraId = headset . findCamera ( CameraCharacteristics . TYPE_WIDE_ANGLE ); if ( cameraId == null ) return ; headset . openCamera ( cameraId , new CameraDevice . Listener () { @Override public void onOpened ( @NonNull CameraDevice camera ) { /* This is called when the camera was successfully opened. * You can start a capture session here. */ } @Override public void onClosed ( @NonNull CameraDevice camera ) { /* This is called when the camera device is completely closed. */ } @Override public void onDisconnected ( @NonNull CameraDevice camera ) { /* This is called when the camera is no longer available. */ } @Override public void onError ( @NonNull CameraDevice camera , int error ) { /* This is called when there is an error with the camera device. */ } }, null ); } Starting a capture session \u00b6 After opening the camera, it must be configured for the output surfaces that are going to be used. The configuration is done by starting a capture session with the createCaptureSession() method. Any output surface that will be used as target of a capture request must be provided when creating the capture session. As for opening a camera device, the creation of a capture session happens asynchronously. The onConfigured() method of the provided listener will be called when the capture session is ready to accept capture requests. The following surface formats are supported. Providing a surface with an unsupported format will result in onConfigureFailed() to be called with error code ERROR_INVALID_OUTPUTS . Surface format Pixel format PixelFormat.RGB_888 24 bits per pixel (Red, Green, Blue) PixelFormat.RGBA_8888 32 bits per pixel (Red, Green, Blue, Alpha) PixelFormat.RGBX_8888 32 bits per pixel (Red, Green, Blue, Padding) PixelFormat.RGB_565 16 bits per pixel (5b Red, 6b Green, 5b Blue) PixelFormat.L_8 Monochrome 8 bits per pixel ImageFormat.Y8 Monochrome 8 bits per pixel ImageFormat.YUY2 Interleaved YUYV with 4:2:2 chroma subsampling ImageFormat.YV12 Planar YUV with 4:2:0 chroma subsampling ImageFormat.JPEG Compressed JPEG Only one capture session may be active per camera device. If you create a new session, the previous session will be closed. You can close the capture session with its close() method. This will asynchronously remove any repeating requests and then wait for all pending capture requests to finish. If you want to stop the session as soon as possible, you can abort the captures first with abortCaptures() . Surface mPreviewSurface ; @Override public void onOpened ( @NonNull CameraDevice camera ) { List < Surface > outputs = new ArrayList <> (); outputs . add ( mPreviewSurface ); camera . createCaptureSession ( outputs , new CaptureSession . Listener () { @Override public void onConfigured ( @NonNull CaptureSession captureSession ) { /* This is called when the capture session is fully configured. * You may start issuing capture requests here. */ } @Override public void onConfigureFailed ( @NonNull CaptureSession captureSession , int error ) { /* This is called when configuring the capture session failed. */ } @Override public void onClosed ( @NonNull CaptureSession captureSession ) { /* This is called when the capture session is closed. * It is no longer possible to issue capture requests. */ } @Override public void onActive ( @NonNull CaptureSession session ) { /* This is called when the camera device actively starts processing * capture requests. */ } @Override public void onCaptureQueueEmpty ( @NonNull CaptureSession session ) { /* This is called when the camera device has no more pending capture * requests and may fall back to the repeating request if set. */ } @Override public void onReady ( @NonNull CaptureSession session ) { /* This is called when the camera device has finished processing all * capture requests and has no repeating request set. */ } }, null ); } Creating a capture request \u00b6 Once the capture session is configured, the camera device is ready to process capture requests. A capture request allows to capture an individual frame of the camera. It may be submitted multiple times, or set as a repeating request, to capture consecutive frames. A capture request specifies the target surfaces and specific camera settings. Capture requests are created with a CaptureRequest.Builder . The createCaptureRequest() method will create a new builder and configure it for a specific use case. Then, you can set the output surfaces and fine tune the settings. Finally, use the build() method to create an immutable capture request. CaptureRequest createCaptureRequest ( CameraDevice camera ) { /* Create the builder. */ CaptureRequest . Builder builder = camera . createCaptureRequest ( CameraDevice . TEMPLATE_PREVIEW ); /* Add the target surface(s) */ builder . addTarget ( mPreviewSurface ); /* Set capture settings (e.g., zoom level). */ builder . set ( CaptureRequest . SCALER_ZOOM , 2 ); /* Build the capture request. */ return builder . build (); } You can now submit capture requests to the capture session. For one-shot image captures or a small burst of captures, use capture() or captureBurst() . For repeated captures, such as video recording or a camera preview, use setRepeatingRequest() . You can stop the repeating request with stopRepeating() . In order to be notified of the progress of the submitted capture requests, you can provide a CaptureListener2 . A capture sequence denotes a set of capture requests that have been submitted together. The capture listener allows tracking the progress of both individual captures and complete sequence. class MyCaptureListener extends CaptureListener2 { @Override public void onCaptureStarted ( @NonNull CaptureSession session , @NonNull CaptureRequest request , long frameNumber ) { /* This is called when the camera device starts processing a capture * request. This is the appropriate time to play a shutter sound * effect or trigger UI indicators. */ } @Override public void onCaptureBufferLost ( @NonNull CaptureSession session , @NonNull CaptureRequest request , @NonNull Surface surface , long frameNumber ) { /* This is called when a buffer for capture data could not be sent to * its destination surface. */ } @Override public void onCaptureCompleted ( @NonNull CaptureSession session , @NonNull CaptureRequest request , @NonNull CaptureResult result ) { /* This is called when an image capture has completed successfully. */ } @Override public void onPostProcessCompleted ( @NonNull CaptureSession session , @NonNull CaptureRequest request , @NonNull CaptureResult result ) { /* This may be called after onCaptureCompleted when post-processing * has been requested, e.g., when scanning barcodes. The result object * will contain the same information as onCaptureCompleted plus the * results of the post-processing. */ } @Override public void onCaptureFailed ( @NonNull CaptureSession session , @NonNull CaptureRequest request , @NonNull CaptureFailure failure ) { /* This is called when a capture failed. */ } @Override public void onCaptureSequenceCompleted ( @NonNull CaptureSession session , int sequenceId , long frameNumber ) { /* This is called when all captures of a capture sequence are * finished, i.e., onCaptureCompleted or onCaptureFailed has been * called for all capture requests in the sequence. */ } @Override public void onCaptureSequenceAborted ( @NonNull CaptureSession session , int sequenceId ) { /* This is called when a capture sequence aborts before any * CaptureResult or CaptureFailure for it have been returned * via this listener. */ } }", "title": "Cameras"}, {"location": "guides/cameras.html#cameras", "text": "The cameras on Iristick smart glasses are accessible only through the camera package . This package contains a set of classes and interfaces for opening camera devices , starting capture sessions and capturing frames with capture requests . This package is loosely modeled after the standard Android camera2 API. Example code The Camera Example provided in the SDK package shows how to use the Camera API. It shows a preview of both cameras on the display. The example shows how to adjust zoom and offset, and how to trigger auto-focus.", "title": "Cameras"}, {"location": "guides/cameras.html#querying-cameras", "text": "Every camera device has a unique identifier. You can find the identifier of a camera with the findCamera() method of a Headset object, providing the desired type of camera. @Override public void onHeadsetConnected ( @NonNull Headset headset ) { String center = headset . findCamera ( CameraCharacteristics . TYPE_WIDE_ANGLE ); if ( center != null ) { // This headset has a wide-angle center camera. // Do something with it. } String zoom = headset . findCamera ( CameraCharacteristics . TYPE_ZOOM ); if ( zoom != null ) { // This headset has a zoom camera. // Do something with it. } } Alternatively, you can get a list of all available camera devices with the getCameraIdList() method of a Headset object. With an identifier, you can query the properties and capabilities of the corresponding camera with getCameraCharacteristics() . /** * Test if the camera device identified by cameraId supports 720p streaming. */ boolean supportsHD ( @NonNull Headset headset , @NonNull String cameraId ) { /* Get the characteristics for this specific camera. */ CameraCharacteristics characteristics = headset . getCameraCharacteristics ( cameraId ); /* Query the supported stream mapping. */ StreamConfigurationMap mapping = characteristics . get ( CameraCharacteristics . SCALER_STREAM_CONFIGURATION_MAP ) /* Test if 720p is in the list of supported sizes. */ for ( Point size : mapping . getSizes ()) { if ( size . x == 1280 && size . y == 720 ) return true ; } return false ; }", "title": "Querying cameras"}, {"location": "guides/cameras.html#opening-a-camera", "text": "The camera device is opened asynchronously with a call to openCamera() , supplying the identifier of the camera and an implementation of CameraDevice.Listener . The listener's onOpened method will be called when the camera is successfully opened. Important Opening a camera device requires the CAMERA permission. You can close the camera device with its close() method. This will close the active capture session. When another app has already opened a camera device, that app will be disconnected from the camera device and must reopen it in order to capture images again. @Override public void onHeadsetConnected ( @NonNull Headset headset ) { /* Open wide-angle center camera. */ String cameraId = headset . findCamera ( CameraCharacteristics . TYPE_WIDE_ANGLE ); if ( cameraId == null ) return ; headset . openCamera ( cameraId , new CameraDevice . Listener () { @Override public void onOpened ( @NonNull CameraDevice camera ) { /* This is called when the camera was successfully opened. * You can start a capture session here. */ } @Override public void onClosed ( @NonNull CameraDevice camera ) { /* This is called when the camera device is completely closed. */ } @Override public void onDisconnected ( @NonNull CameraDevice camera ) { /* This is called when the camera is no longer available. */ } @Override public void onError ( @NonNull CameraDevice camera , int error ) { /* This is called when there is an error with the camera device. */ } }, null ); }", "title": "Opening a camera"}, {"location": "guides/cameras.html#starting-a-capture-session", "text": "After opening the camera, it must be configured for the output surfaces that are going to be used. The configuration is done by starting a capture session with the createCaptureSession() method. Any output surface that will be used as target of a capture request must be provided when creating the capture session. As for opening a camera device, the creation of a capture session happens asynchronously. The onConfigured() method of the provided listener will be called when the capture session is ready to accept capture requests. The following surface formats are supported. Providing a surface with an unsupported format will result in onConfigureFailed() to be called with error code ERROR_INVALID_OUTPUTS . Surface format Pixel format PixelFormat.RGB_888 24 bits per pixel (Red, Green, Blue) PixelFormat.RGBA_8888 32 bits per pixel (Red, Green, Blue, Alpha) PixelFormat.RGBX_8888 32 bits per pixel (Red, Green, Blue, Padding) PixelFormat.RGB_565 16 bits per pixel (5b Red, 6b Green, 5b Blue) PixelFormat.L_8 Monochrome 8 bits per pixel ImageFormat.Y8 Monochrome 8 bits per pixel ImageFormat.YUY2 Interleaved YUYV with 4:2:2 chroma subsampling ImageFormat.YV12 Planar YUV with 4:2:0 chroma subsampling ImageFormat.JPEG Compressed JPEG Only one capture session may be active per camera device. If you create a new session, the previous session will be closed. You can close the capture session with its close() method. This will asynchronously remove any repeating requests and then wait for all pending capture requests to finish. If you want to stop the session as soon as possible, you can abort the captures first with abortCaptures() . Surface mPreviewSurface ; @Override public void onOpened ( @NonNull CameraDevice camera ) { List < Surface > outputs = new ArrayList <> (); outputs . add ( mPreviewSurface ); camera . createCaptureSession ( outputs , new CaptureSession . Listener () { @Override public void onConfigured ( @NonNull CaptureSession captureSession ) { /* This is called when the capture session is fully configured. * You may start issuing capture requests here. */ } @Override public void onConfigureFailed ( @NonNull CaptureSession captureSession , int error ) { /* This is called when configuring the capture session failed. */ } @Override public void onClosed ( @NonNull CaptureSession captureSession ) { /* This is called when the capture session is closed. * It is no longer possible to issue capture requests. */ } @Override public void onActive ( @NonNull CaptureSession session ) { /* This is called when the camera device actively starts processing * capture requests. */ } @Override public void onCaptureQueueEmpty ( @NonNull CaptureSession session ) { /* This is called when the camera device has no more pending capture * requests and may fall back to the repeating request if set. */ } @Override public void onReady ( @NonNull CaptureSession session ) { /* This is called when the camera device has finished processing all * capture requests and has no repeating request set. */ } }, null ); }", "title": "Starting a capture session"}, {"location": "guides/cameras.html#creating-a-capture-request", "text": "Once the capture session is configured, the camera device is ready to process capture requests. A capture request allows to capture an individual frame of the camera. It may be submitted multiple times, or set as a repeating request, to capture consecutive frames. A capture request specifies the target surfaces and specific camera settings. Capture requests are created with a CaptureRequest.Builder . The createCaptureRequest() method will create a new builder and configure it for a specific use case. Then, you can set the output surfaces and fine tune the settings. Finally, use the build() method to create an immutable capture request. CaptureRequest createCaptureRequest ( CameraDevice camera ) { /* Create the builder. */ CaptureRequest . Builder builder = camera . createCaptureRequest ( CameraDevice . TEMPLATE_PREVIEW ); /* Add the target surface(s) */ builder . addTarget ( mPreviewSurface ); /* Set capture settings (e.g., zoom level). */ builder . set ( CaptureRequest . SCALER_ZOOM , 2 ); /* Build the capture request. */ return builder . build (); } You can now submit capture requests to the capture session. For one-shot image captures or a small burst of captures, use capture() or captureBurst() . For repeated captures, such as video recording or a camera preview, use setRepeatingRequest() . You can stop the repeating request with stopRepeating() . In order to be notified of the progress of the submitted capture requests, you can provide a CaptureListener2 . A capture sequence denotes a set of capture requests that have been submitted together. The capture listener allows tracking the progress of both individual captures and complete sequence. class MyCaptureListener extends CaptureListener2 { @Override public void onCaptureStarted ( @NonNull CaptureSession session , @NonNull CaptureRequest request , long frameNumber ) { /* This is called when the camera device starts processing a capture * request. This is the appropriate time to play a shutter sound * effect or trigger UI indicators. */ } @Override public void onCaptureBufferLost ( @NonNull CaptureSession session , @NonNull CaptureRequest request , @NonNull Surface surface , long frameNumber ) { /* This is called when a buffer for capture data could not be sent to * its destination surface. */ } @Override public void onCaptureCompleted ( @NonNull CaptureSession session , @NonNull CaptureRequest request , @NonNull CaptureResult result ) { /* This is called when an image capture has completed successfully. */ } @Override public void onPostProcessCompleted ( @NonNull CaptureSession session , @NonNull CaptureRequest request , @NonNull CaptureResult result ) { /* This may be called after onCaptureCompleted when post-processing * has been requested, e.g., when scanning barcodes. The result object * will contain the same information as onCaptureCompleted plus the * results of the post-processing. */ } @Override public void onCaptureFailed ( @NonNull CaptureSession session , @NonNull CaptureRequest request , @NonNull CaptureFailure failure ) { /* This is called when a capture failed. */ } @Override public void onCaptureSequenceCompleted ( @NonNull CaptureSession session , int sequenceId , long frameNumber ) { /* This is called when all captures of a capture sequence are * finished, i.e., onCaptureCompleted or onCaptureFailed has been * called for all capture requests in the sequence. */ } @Override public void onCaptureSequenceAborted ( @NonNull CaptureSession session , int sequenceId ) { /* This is called when a capture sequence aborts before any * CaptureResult or CaptureFailure for it have been returned * via this listener. */ } }", "title": "Creating a capture request"}, {"location": "guides/display.html", "text": "Display \u00b6 Iristick smart glasses have a small display on the right side, located on a movable arm. The following table shows the display resolution for various Iristick models. Applications should however be able to handle other display sizes. Models Resolution G1 / G2 428 \u00d7 240 H1 640 \u00d7 400 By default, the display mirrors the content of the phone screen. This behavior can be overridden to either show custom UI with standard Android widgets and layouts, or to draw directly to the underlying surface. Tip Please read the Getting Started guide for a discussion on the default behavior of the display. Example code The Clock Display Example provided in the SDK package shows how to draw standard UI elements on the display. It uses a TextView to show a clock. The Bubbles Display Example shows how to directly draw on the display using the 2D drawing API of the Canvas class. It shows a bunch of colored bubbles floating around on the display. Opening the display \u00b6 Before any drawing can occur, the display must first be opened. The Headset objects provides two methods for this: openDisplay() results in a Display object for drawing Android widgets; openDisplaySurface() results in a Surface for direct drawing. @Override public void onHeadsetConnected ( @NonNull Headset headset ) { headset . openDisplay ( new DisplayListener () { @Override public void onDisplayOpened ( @NonNull Display display ) { /* This method is called when the display is opened and ready * for use. */ } @Override public void onDisplaySurfaceOpened ( @NonNull Surface surface , int width , int height , int density ) { /* This method would have been called instead of onDisplayOpened * if we had opened the display with openDisplaySurface(). */ } @Override public void onDisplayClosed ( int reason ) { /* This method is called when the display is closed. * It is also called instead of the above two methods if the * display could not be opened. */ } }, null ); } When you no longer need the display, you can close it with a call to the closeDisplay() method of the Headset object. Note The display can only be opened by one application at the same time. Trying to open the display while another app is drawing on it, will result in an error (if the requesting app has lower priority) or closing the display in the other app (if the requesting app has higher priority, e.g., it is in foreground). Likewise, it is not possible to open the display twice. You have to close it first before you can reopen it. Drawing standard widgets \u00b6 To show a window with standard UI elements on the Iristick display, subclass the Presentation class. A Presentation is a special kind of dialog window that displays its content on a secondary display. Presentation automatically adapt resources to the dimensions and density of the secondary display. class MyPresentation extends Presentation { MyPresentation ( @NonNull Context outerContext , @NonNull Display display ) { super ( outerContext , display ); /* Prevent widgets on the display from stealing focus. */ getWindow (). setFlags ( WindowManager . LayoutParams . FLAG_NOT_FOCUSABLE , WindowManager . LayoutParams . FLAG_NOT_FOCUSABLE ); } @Override protected void onCreate ( @Nullable Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ); setContentView ( R . layout . presentation_screen ); /* Perform any initialization here, such as retrieving widgets * with findViewById(). */ } @Override public void onStop () { /* Called when the presentation is dismissed. Do cleanup here. */ super . onStop (); } } The presentation is closely linked to the display on which it shows its contents. It requires a Display object representing the secondary display as an argument to its constructor. You can get this object by opening the display with the openDisplay() method of the Headset object. When opening the display was successful, the onDisplayOpened() of your display listener is called. You can create and show your presentation there. @Override public void onDisplayOpened ( @NonNull Display display ) { new MyPresentation ( this , display ). show (); } Presentations are automatically dismissed when the display is closed. Note You must use the Context provided by the presentation for layouts and views shown in the presentation and the regular activity context or fragment context for layouts and views shown on the screen of the phone. This ensures proper scaling of the views and text. You can get the presentation's context with the presentation's getContext() method. Drawing directly on the display \u00b6 To directly draw on the display bypassing the Android view hierarchy, open the display with openDisplaySurface() to get a Surface object representing the raw display surface. Surface objects can be used at multiple places in the Android API. For example, one can call lockCanvas() to use the Canvas 2D drawing API.", "title": "Display"}, {"location": "guides/display.html#display", "text": "Iristick smart glasses have a small display on the right side, located on a movable arm. The following table shows the display resolution for various Iristick models. Applications should however be able to handle other display sizes. Models Resolution G1 / G2 428 \u00d7 240 H1 640 \u00d7 400 By default, the display mirrors the content of the phone screen. This behavior can be overridden to either show custom UI with standard Android widgets and layouts, or to draw directly to the underlying surface. Tip Please read the Getting Started guide for a discussion on the default behavior of the display. Example code The Clock Display Example provided in the SDK package shows how to draw standard UI elements on the display. It uses a TextView to show a clock. The Bubbles Display Example shows how to directly draw on the display using the 2D drawing API of the Canvas class. It shows a bunch of colored bubbles floating around on the display.", "title": "Display"}, {"location": "guides/display.html#opening-the-display", "text": "Before any drawing can occur, the display must first be opened. The Headset objects provides two methods for this: openDisplay() results in a Display object for drawing Android widgets; openDisplaySurface() results in a Surface for direct drawing. @Override public void onHeadsetConnected ( @NonNull Headset headset ) { headset . openDisplay ( new DisplayListener () { @Override public void onDisplayOpened ( @NonNull Display display ) { /* This method is called when the display is opened and ready * for use. */ } @Override public void onDisplaySurfaceOpened ( @NonNull Surface surface , int width , int height , int density ) { /* This method would have been called instead of onDisplayOpened * if we had opened the display with openDisplaySurface(). */ } @Override public void onDisplayClosed ( int reason ) { /* This method is called when the display is closed. * It is also called instead of the above two methods if the * display could not be opened. */ } }, null ); } When you no longer need the display, you can close it with a call to the closeDisplay() method of the Headset object. Note The display can only be opened by one application at the same time. Trying to open the display while another app is drawing on it, will result in an error (if the requesting app has lower priority) or closing the display in the other app (if the requesting app has higher priority, e.g., it is in foreground). Likewise, it is not possible to open the display twice. You have to close it first before you can reopen it.", "title": "Opening the display"}, {"location": "guides/display.html#drawing-standard-widgets", "text": "To show a window with standard UI elements on the Iristick display, subclass the Presentation class. A Presentation is a special kind of dialog window that displays its content on a secondary display. Presentation automatically adapt resources to the dimensions and density of the secondary display. class MyPresentation extends Presentation { MyPresentation ( @NonNull Context outerContext , @NonNull Display display ) { super ( outerContext , display ); /* Prevent widgets on the display from stealing focus. */ getWindow (). setFlags ( WindowManager . LayoutParams . FLAG_NOT_FOCUSABLE , WindowManager . LayoutParams . FLAG_NOT_FOCUSABLE ); } @Override protected void onCreate ( @Nullable Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ); setContentView ( R . layout . presentation_screen ); /* Perform any initialization here, such as retrieving widgets * with findViewById(). */ } @Override public void onStop () { /* Called when the presentation is dismissed. Do cleanup here. */ super . onStop (); } } The presentation is closely linked to the display on which it shows its contents. It requires a Display object representing the secondary display as an argument to its constructor. You can get this object by opening the display with the openDisplay() method of the Headset object. When opening the display was successful, the onDisplayOpened() of your display listener is called. You can create and show your presentation there. @Override public void onDisplayOpened ( @NonNull Display display ) { new MyPresentation ( this , display ). show (); } Presentations are automatically dismissed when the display is closed. Note You must use the Context provided by the presentation for layouts and views shown in the presentation and the regular activity context or fragment context for layouts and views shown on the screen of the phone. This ensures proper scaling of the views and text. You can get the presentation's context with the presentation's getContext() method.", "title": "Drawing standard widgets"}, {"location": "guides/display.html#drawing-directly-on-the-display", "text": "To directly draw on the display bypassing the Android view hierarchy, open the display with openDisplaySurface() to get a Surface object representing the raw display surface. Surface objects can be used at multiple places in the Android API. For example, one can call lockCanvas() to use the Canvas 2D drawing API.", "title": "Drawing directly on the display"}, {"location": "guides/sensors.html", "text": "Sensors \u00b6 Iristick smart glasses feature additional sensors: accelerometer, gyroscope, and magnetometer. The Iristick.G1 also features a fusion algorithm to provide the absolute orientation of the glasses with respect to the earth surface and the magnetic North. Such algorithm is not yet available on the Iristick.G2 and Iristick.H1. Example code The Sensors Readout Example provided in the SDK package provides a minimal example on how to use the Sensors API. It reads out the values of all sensors and show them on the main phone display. In order to get data from one of these sensors, you have to implement and register a SensorEventListener . A listener is registered with a given rate at which you want to receive data. The desired rate is expressed as an interval in microseconds. The actual rate may be faster or slower. @Override public void onHeadsetConnected ( @NonNull Headset headset ) { /* Listen to the accelerometer with a desired refresh rate of twice * per second. */ Sensor gravitySensor = headset . getDefaultSensor ( Sensor . TYPE_ACCELEROMETER ); gravitySensor . registerListener ( new SensorEventListener () { @Override public void onSensorChanged ( @NonNull SensorEvent event ) { /* Do something with data in event.values. */ } }, 500000 ); } When you no longer need the sensor data, you can unregister your listener with a call to unregisterListener() . Alternatively, you can unregister a listener from all sensors with unregisterSensorListener() .", "title": "Sensors"}, {"location": "guides/sensors.html#sensors", "text": "Iristick smart glasses feature additional sensors: accelerometer, gyroscope, and magnetometer. The Iristick.G1 also features a fusion algorithm to provide the absolute orientation of the glasses with respect to the earth surface and the magnetic North. Such algorithm is not yet available on the Iristick.G2 and Iristick.H1. Example code The Sensors Readout Example provided in the SDK package provides a minimal example on how to use the Sensors API. It reads out the values of all sensors and show them on the main phone display. In order to get data from one of these sensors, you have to implement and register a SensorEventListener . A listener is registered with a given rate at which you want to receive data. The desired rate is expressed as an interval in microseconds. The actual rate may be faster or slower. @Override public void onHeadsetConnected ( @NonNull Headset headset ) { /* Listen to the accelerometer with a desired refresh rate of twice * per second. */ Sensor gravitySensor = headset . getDefaultSensor ( Sensor . TYPE_ACCELEROMETER ); gravitySensor . registerListener ( new SensorEventListener () { @Override public void onSensorChanged ( @NonNull SensorEvent event ) { /* Do something with data in event.values. */ } }, 500000 ); } When you no longer need the sensor data, you can unregister your listener with a call to unregisterListener() . Alternatively, you can unregister a listener from all sensors with unregisterSensorListener() .", "title": "Sensors"}, {"location": "guides/touchpad.html", "text": "Touchpad \u00b6 The touchpad on Iristick smart glasses is used to navigate through the widgets when the heads-up display mirrors the content of the phone screen. This behavior can be overridden to process touch events manually. There are two kinds of touch events: simple gestures and precise finger movements. In both cases, the app has to call the Headset.registerTouchEventCallback method. This is best done in the onResume method. @Override protected void onResume () { super . onResume (); Headset headset = IristickApp . getHeadset (); if ( headset != null ) { headset . registerTouchEventCallback ( new TouchEvent . Callback () { @Override public void onTouchEvent ( @NonNull TouchEvent event ) { /* Process the touch event here: * event.getGestureCode() returns the simple gesture that was * recognized, or TouchEvent.GESTURE_NONE if none; * event.getMotionEvent() returns the precise motion data or * null if such data is not available. */ } }, null ); } } By default, registering a touchpad callback disables the default navigation system which allows users to interact with on-screen widgets. There is one exception though: swiping down will continue triggering a \"back\" action for consistency with other apps. To override this behavior, pass additional flags to registerCallback . You can unregister the callback with the Headset.unregisterTouchEventCallback() method to stop receiving touch events. Attention Always unregister touch callbacks in your activity's onPause() to give control back to the default navigation system. Example code The Touchpad Example provided in the SDK package provides an example on how to use the Touchpad API. It shows the gestures that were made on the touchpad. It also enables the user to move a drawing cursor on the main phone display by moving a finger over the touchpad. Simple interaction via gestures \u00b6 The touchpad of the Iristick smart glasses can distinguish between several specific gestures. The following gestures are recognized: Single tap : the user briefly touches the touchpad; Double tap : the user taps twice in quick succession; Long tap : similar to a single tap, but held for a longer time; Swipe forward : the user swipes their finger over the touchpad from the back towards the front, away from their ear; Swipe backward : the user swipes their finger over the touchpad from the front towards the back, towards their ear; Swipe down : the user swipes their finger over the touchpad in a downward motion; Use the getGestureCode() method to determine which gesture, if any, was performed. Precise control with MotionEvents \u00b6 Some use cases require more precise, fluid or continuous control. For these cases, the touch event contains a MotionEvent object, describing the exact finger movement over the touchpad. The X and Y coordinates of the motion events represent the current absolute position of the finger on the touchpad with (0, 0) located at the bottom left corner of the touchpad near the ear and (1, 1) located at the upper right corner near the front of the glasses. The action of the motion events describe what the finger is currently doing with the touchpad. The following actions are supported: ACTION_DOWN : the finger has started touching the touchpad; ACTION_MOVE : the finger continues to touch the touchpad; ACTION_UP : the finger is lifted from the touchpad; ACTION_HOVER_MOVE : a gesture is recognized after the finger was lifted from the touchpad. You will most probably want to ignore any event with this action.", "title": "Touchpad"}, {"location": "guides/touchpad.html#touchpad", "text": "The touchpad on Iristick smart glasses is used to navigate through the widgets when the heads-up display mirrors the content of the phone screen. This behavior can be overridden to process touch events manually. There are two kinds of touch events: simple gestures and precise finger movements. In both cases, the app has to call the Headset.registerTouchEventCallback method. This is best done in the onResume method. @Override protected void onResume () { super . onResume (); Headset headset = IristickApp . getHeadset (); if ( headset != null ) { headset . registerTouchEventCallback ( new TouchEvent . Callback () { @Override public void onTouchEvent ( @NonNull TouchEvent event ) { /* Process the touch event here: * event.getGestureCode() returns the simple gesture that was * recognized, or TouchEvent.GESTURE_NONE if none; * event.getMotionEvent() returns the precise motion data or * null if such data is not available. */ } }, null ); } } By default, registering a touchpad callback disables the default navigation system which allows users to interact with on-screen widgets. There is one exception though: swiping down will continue triggering a \"back\" action for consistency with other apps. To override this behavior, pass additional flags to registerCallback . You can unregister the callback with the Headset.unregisterTouchEventCallback() method to stop receiving touch events. Attention Always unregister touch callbacks in your activity's onPause() to give control back to the default navigation system. Example code The Touchpad Example provided in the SDK package provides an example on how to use the Touchpad API. It shows the gestures that were made on the touchpad. It also enables the user to move a drawing cursor on the main phone display by moving a finger over the touchpad.", "title": "Touchpad"}, {"location": "guides/touchpad.html#simple-interaction-via-gestures", "text": "The touchpad of the Iristick smart glasses can distinguish between several specific gestures. The following gestures are recognized: Single tap : the user briefly touches the touchpad; Double tap : the user taps twice in quick succession; Long tap : similar to a single tap, but held for a longer time; Swipe forward : the user swipes their finger over the touchpad from the back towards the front, away from their ear; Swipe backward : the user swipes their finger over the touchpad from the front towards the back, towards their ear; Swipe down : the user swipes their finger over the touchpad in a downward motion; Use the getGestureCode() method to determine which gesture, if any, was performed.", "title": "Simple interaction via gestures"}, {"location": "guides/touchpad.html#precise-control-with-motionevents", "text": "Some use cases require more precise, fluid or continuous control. For these cases, the touch event contains a MotionEvent object, describing the exact finger movement over the touchpad. The X and Y coordinates of the motion events represent the current absolute position of the finger on the touchpad with (0, 0) located at the bottom left corner of the touchpad near the ear and (1, 1) located at the upper right corner near the front of the glasses. The action of the motion events describe what the finger is currently doing with the touchpad. The following actions are supported: ACTION_DOWN : the finger has started touching the touchpad; ACTION_MOVE : the finger continues to touch the touchpad; ACTION_UP : the finger is lifted from the touchpad; ACTION_HOVER_MOVE : a gesture is recognized after the finger was lifted from the touchpad. You will most probably want to ignore any event with this action.", "title": "Precise control with MotionEvents"}, {"location": "guides/voice.html", "text": "Voice \u00b6 Some Iristick smart glasses models, such as the Iristick.G1 PRO, Iristick.G2 PRO and Iristick.H1, can be controlled with voice commands. By default, when the phone display is mirrored in the heads-up display, voice commands for clickable elements will be discovered using the android:contentDescription layout property. If that property is not specified, a voice command may be inferred from the displayed text. The language of the voice recognition engine is derived from the primary system language. If the system language is not supported, English will be used as fallback. The following languages are supported: English French Using the API, applications may customize the behavior of voice commands and register additional voice commands that are independent of elements shown on the screen. Note On models without voice recognition, voice commands will be ignored. Using the API to configure or register voice commands will not throw any error. Voice commands may also be disabled by the user through a setting of the Iristick Services. Built-in voice commands \u00b6 Info Built-in voice commands are not part of the stable API and may change between releases. Global commands \u00b6 The following commands are always available unless disabled by API. Action English French Simulate back button Go backwards Retourner Scroll down 1 Scroll next page D\u00e9filer en avant Scroll up 1 Scroll previous page D\u00e9filer en arri\u00e8re Put phone to sleep Iristick suspend Iristick mettre en veille Wake up phone Iristick wake up Iristick r\u00e9veil Keyboard \u00b6 The following commands are available when the Iristick on-screen keyboard is shown. Action English French Insert letter Letter Lettre Insert digit Digit Chiffre Insert symbol Symbol Symbole Switch to lowercase Lowercase Minuscule Switch to uppercase Uppercase Majuscule Lock uppercase All uppercase Tout en majuscules Close keyboard Close keyboard Fermer clavier Delete last character Backspace character Effacer caract\u00e8re Delete last word Backspace word Effacer mot Delete last line Backspace line Effacer ligne Delete everything Clear all Effacer tout Tip Multiple letter, digits or symbols may be spelled at once after saying the character category (e.g., saying Digit 4 2 will enter 42 ). Letters may be spelled using the NATO alphabet for increased precision. Camera \u00b6 The following commands are available when opening the standalone Iristick camera app, or in the ACTION_IMAGE_CAPTURE intent. Action English French Take picture Capture Capturer Toggle center/zoom camera Switch camera Changer de cam\u00e9ra Go to movie recorder 2 Record video Enregister une vid\u00e9o The following commands are available when going to the movie recorder in the standalone Iristick camera app, or in the ACTION_VIDEO_CAPTURE intent. Action English French Start recording video Start recording D\u00e9marrer enregistrement Stop recording video Stop recording Arr\u00eater enregistrement Temporarily pause recording Pause recording Interrompre enregistrement Resume paused recording Resume recording Reprendre enregistrement Toggle center/zoom camera Switch camera Changer de cam\u00e9ra Go to still capture mode 2 Take a picture Prendre une photo The following commands are available after taking a picture or recording a video through an intent to confirm the capture (the standalone Iristick camera app does not show the confirmation view). Action English French Confirm and return to app Confirm Confirmer Launch movie player Replay video Revoir vid\u00e9o Barcode scanner \u00b6 The following commands are available in the ACTION_SCAN_BARCODE intent. Action English French Toggle flashlight Flashlight Lampe de poche Image viewer \u00b6 The following commands are available in the ACTION_VIEW intent. Action English French Zoom in Zoom in Zoom avant Zoom out Zoom out Zoom arri\u00e8re Unlock moving around Start moving D\u00e9marrer panoramique Lock moving around Stop moving Arr\u00eater panoramique Go to overview Show overview Vue d'ensemble Go back to detail Show detail Vue de d\u00e9tail Scroll down/up actions are only available if there is a single scrollable view visible. \u21a9 \u21a9 Only available in the standalone Iristick camera app \u21a9 \u21a9", "title": "Voice"}, {"location": "guides/voice.html#voice", "text": "Some Iristick smart glasses models, such as the Iristick.G1 PRO, Iristick.G2 PRO and Iristick.H1, can be controlled with voice commands. By default, when the phone display is mirrored in the heads-up display, voice commands for clickable elements will be discovered using the android:contentDescription layout property. If that property is not specified, a voice command may be inferred from the displayed text. The language of the voice recognition engine is derived from the primary system language. If the system language is not supported, English will be used as fallback. The following languages are supported: English French Using the API, applications may customize the behavior of voice commands and register additional voice commands that are independent of elements shown on the screen. Note On models without voice recognition, voice commands will be ignored. Using the API to configure or register voice commands will not throw any error. Voice commands may also be disabled by the user through a setting of the Iristick Services.", "title": "Voice"}, {"location": "guides/voice.html#built-in-voice-commands", "text": "Info Built-in voice commands are not part of the stable API and may change between releases.", "title": "Built-in voice commands"}, {"location": "guides/voice.html#global-commands", "text": "The following commands are always available unless disabled by API. Action English French Simulate back button Go backwards Retourner Scroll down 1 Scroll next page D\u00e9filer en avant Scroll up 1 Scroll previous page D\u00e9filer en arri\u00e8re Put phone to sleep Iristick suspend Iristick mettre en veille Wake up phone Iristick wake up Iristick r\u00e9veil", "title": "Global commands"}, {"location": "guides/voice.html#keyboard", "text": "The following commands are available when the Iristick on-screen keyboard is shown. Action English French Insert letter Letter Lettre Insert digit Digit Chiffre Insert symbol Symbol Symbole Switch to lowercase Lowercase Minuscule Switch to uppercase Uppercase Majuscule Lock uppercase All uppercase Tout en majuscules Close keyboard Close keyboard Fermer clavier Delete last character Backspace character Effacer caract\u00e8re Delete last word Backspace word Effacer mot Delete last line Backspace line Effacer ligne Delete everything Clear all Effacer tout Tip Multiple letter, digits or symbols may be spelled at once after saying the character category (e.g., saying Digit 4 2 will enter 42 ). Letters may be spelled using the NATO alphabet for increased precision.", "title": "Keyboard"}, {"location": "guides/voice.html#camera", "text": "The following commands are available when opening the standalone Iristick camera app, or in the ACTION_IMAGE_CAPTURE intent. Action English French Take picture Capture Capturer Toggle center/zoom camera Switch camera Changer de cam\u00e9ra Go to movie recorder 2 Record video Enregister une vid\u00e9o The following commands are available when going to the movie recorder in the standalone Iristick camera app, or in the ACTION_VIDEO_CAPTURE intent. Action English French Start recording video Start recording D\u00e9marrer enregistrement Stop recording video Stop recording Arr\u00eater enregistrement Temporarily pause recording Pause recording Interrompre enregistrement Resume paused recording Resume recording Reprendre enregistrement Toggle center/zoom camera Switch camera Changer de cam\u00e9ra Go to still capture mode 2 Take a picture Prendre une photo The following commands are available after taking a picture or recording a video through an intent to confirm the capture (the standalone Iristick camera app does not show the confirmation view). Action English French Confirm and return to app Confirm Confirmer Launch movie player Replay video Revoir vid\u00e9o", "title": "Camera"}, {"location": "guides/voice.html#barcode-scanner", "text": "The following commands are available in the ACTION_SCAN_BARCODE intent. Action English French Toggle flashlight Flashlight Lampe de poche", "title": "Barcode scanner"}, {"location": "guides/voice.html#image-viewer", "text": "The following commands are available in the ACTION_VIEW intent. Action English French Zoom in Zoom in Zoom avant Zoom out Zoom out Zoom arri\u00e8re Unlock moving around Start moving D\u00e9marrer panoramique Lock moving around Stop moving Arr\u00eater panoramique Go to overview Show overview Vue d'ensemble Go back to detail Show detail Vue de d\u00e9tail Scroll down/up actions are only available if there is a single scrollable view visible. \u21a9 \u21a9 Only available in the standalone Iristick camera app \u21a9 \u21a9", "title": "Image viewer"}, {"location": "release-notes/1.1.html", "text": "What's new in Iristick SDK 1.1 \u00b6 This is a minor feature release that is backward-compatible with previous 1.0 releases. Applications built with SDK 1.0 will continue to work with Iristick Services 1.1 without recompiling. Applications built with SDK 1.1 however require Iristick Services 1.1 or later to be installed. Extended voice commands \u00b6 The Iristick Services got a French translation and learned to understand French voice commands. The new language support will be automatically selected when French is selected as primary language in the Android settings. Have a look at the voice API guide for the list of translated built-in voice commands. Two new global voice commands have been added to suspend (say Iristick suspend ) and wake up the phone (say Iristick wake up ). The new commands can be disabled in the Iristick Services settings if they are not desired or to save power. API additions \u00b6 New APIs allow to better introspect the state of connected devices. The Headset class got a getSerialNumber() method to retrieve the serial number of a connected headset. The new IristickConnection2 abstract class can be extended instead of IristickConnection to get notified of global services state changes and connected pocket units. The PocketUnit objects can then be used to retrieve the serial number and battery level of the connected pocket unit. Interaction rules learned the KEYBOARD_VOICE key to allow the application's voice commands to still be recognized while the keyboard is open. The ACTION_VIEW intent now looks for an EXTRA_EXIT_ON_ZOOM_OUT extra. If set to true, the image viewer will close when the user asks to zoom out through a voice command while the view is already completely zoomed out. Note that this has no effect when using the touchscreen or the headset's touchpad. The ERROR_NOT_INSTALLED error code in IristickConnection has been split into ERROR_NOT_INSTALLED_UNATTACHED and ERROR_NOT_INSTALLED_ATTACHED codes. This allows to detect the presence of an attached pocket unit even when the Iristick Services are not installed on the phone. Other changes \u00b6 The ACTION_SCAN_BARCODE intent now shows a button to turn the flashlight on or off when scanning for a barcode. The flashlight can also be controlled with the flashlight voice command. The brightness of the heads-up display can now be set in the Iristick Services settings. The backlight of the heads-up display will also automatically turn off when the phone is suspended. Deprecation notices \u00b6 The ERROR_NOT_INSTALLED error code of IristickConnection is now an alias for ERROR_NOT_INSTALLED_UNATTACHED and has been marked as deprecated. Applications built with SDK 1.1 must be prepared to handle the new ERROR_NOT_INSTALLED_ATTACHED error code. Patch releases since 1.1 \u00b6 Release 1.1.1 \u00b6 The continuous tone in external earpieces has been removed. The LED of the pocket unit now indicates more clearly when the device is charging rapidly. Video recording is not stopped anymore when the screen orientation changes. Miscellaneous bugs have been fixed.", "title": "Release 1.1"}, {"location": "release-notes/1.1.html#whats-new-in-iristick-sdk-11", "text": "This is a minor feature release that is backward-compatible with previous 1.0 releases. Applications built with SDK 1.0 will continue to work with Iristick Services 1.1 without recompiling. Applications built with SDK 1.1 however require Iristick Services 1.1 or later to be installed.", "title": "What's new in Iristick SDK 1.1"}, {"location": "release-notes/1.1.html#extended-voice-commands", "text": "The Iristick Services got a French translation and learned to understand French voice commands. The new language support will be automatically selected when French is selected as primary language in the Android settings. Have a look at the voice API guide for the list of translated built-in voice commands. Two new global voice commands have been added to suspend (say Iristick suspend ) and wake up the phone (say Iristick wake up ). The new commands can be disabled in the Iristick Services settings if they are not desired or to save power.", "title": "Extended voice commands"}, {"location": "release-notes/1.1.html#api-additions", "text": "New APIs allow to better introspect the state of connected devices. The Headset class got a getSerialNumber() method to retrieve the serial number of a connected headset. The new IristickConnection2 abstract class can be extended instead of IristickConnection to get notified of global services state changes and connected pocket units. The PocketUnit objects can then be used to retrieve the serial number and battery level of the connected pocket unit. Interaction rules learned the KEYBOARD_VOICE key to allow the application's voice commands to still be recognized while the keyboard is open. The ACTION_VIEW intent now looks for an EXTRA_EXIT_ON_ZOOM_OUT extra. If set to true, the image viewer will close when the user asks to zoom out through a voice command while the view is already completely zoomed out. Note that this has no effect when using the touchscreen or the headset's touchpad. The ERROR_NOT_INSTALLED error code in IristickConnection has been split into ERROR_NOT_INSTALLED_UNATTACHED and ERROR_NOT_INSTALLED_ATTACHED codes. This allows to detect the presence of an attached pocket unit even when the Iristick Services are not installed on the phone.", "title": "API additions"}, {"location": "release-notes/1.1.html#other-changes", "text": "The ACTION_SCAN_BARCODE intent now shows a button to turn the flashlight on or off when scanning for a barcode. The flashlight can also be controlled with the flashlight voice command. The brightness of the heads-up display can now be set in the Iristick Services settings. The backlight of the heads-up display will also automatically turn off when the phone is suspended.", "title": "Other changes"}, {"location": "release-notes/1.1.html#deprecation-notices", "text": "The ERROR_NOT_INSTALLED error code of IristickConnection is now an alias for ERROR_NOT_INSTALLED_UNATTACHED and has been marked as deprecated. Applications built with SDK 1.1 must be prepared to handle the new ERROR_NOT_INSTALLED_ATTACHED error code.", "title": "Deprecation notices"}, {"location": "release-notes/1.1.html#patch-releases-since-11", "text": "", "title": "Patch releases since 1.1"}, {"location": "release-notes/1.1.html#release-111", "text": "The continuous tone in external earpieces has been removed. The LED of the pocket unit now indicates more clearly when the device is charging rapidly. Video recording is not stopped anymore when the screen orientation changes. Miscellaneous bugs have been fixed.", "title": "Release 1.1.1"}, {"location": "release-notes/1.2.html", "text": "What's new in Iristick SDK 1.2 \u00b6 This is a minor feature release that is backward-compatible with previous 1.x releases. Applications built with SDK 1.0 up to 1.1 will continue to work with Iristick Services 1.2 without recompiling. Applications built with SDK 1.2 however require Iristick Services 1.2 or later to be installed. iOS SDK Preview \u00b6 This release introduces the first preview of the Iristick SDK for iOS devices, allowing iOS applications to run on Iristick smart glasses. The preview SDK is available on request. Please get in touch with Iristick if you are interested. Android 10 support \u00b6 This release adds support for phones running on Android 10. Please note that, due to a bug in Android 10, your pocket unit's firmware may need to be upgraded before it can be used on Android 10. To do so, connect your pocket unit to a phone running on Android 9 or older with Iristick Services 1.2 installed. Android 10 has removed the option to grant screen capture permission to an app without asking every time. To allow smooth operation when headsets get connected and disconnected, the Iristick Services will now request screen capture permission as soon as a pocket unit is connected to the phone. Barcode scanning API \u00b6 In previous releases, barcode scanning was only available through the ACTION_SCAN_BARCODE intent. This release extends the camera API to give developers complete control over the barcode scanning process. The new API can be leveraged to provide continuous barcode scanning and even to scan multiple barcodes at once. The following keys have been added to the camera API: CameraCharacteristics.POSTPROCESS_MAXIMUM_BARCODE_COUNT CameraCharacteristics.POSTPROCESS_AVAILABLE_BARCODE_FORMATS CaptureRequest.POSTPROCESS_MODE CaptureRequest.POSTPROCESS_BARCODE_COUNT CaptureRequest.POSTPROCESS_BARCODE_FORMATS CaptureRequest.POSTPROCESS_BARCODE_TARGET CaptureRequest.POSTPROCESS_BARCODE_TARGET_TOLERANCE CaptureResult.POSTPROCESS_BARCODES Read the new barcode scanning API guide for more information. Other API changes \u00b6 The white balance of the cameras can now be controlled manually. The final white balance gains applied to a frame are also reported as part of the capture results. The corresponding new keys in the camera API are: CameraCharacteristics.CONTROL_AWB_AVAILABLE_MODES CaptureRequest.CONTROL_AWB_MODE CaptureRequest.COLOR_CORRECTION_GAIN_BLUE CaptureRequest.COLOR_CORRECTION_GAIN_RED CaptureResult.COLOR_CORRECTION_GAIN_BLUE CaptureResult.COLOR_CORRECTION_GAIN_RED To make it easier to select an Iristick camera, the Headset class got a new findCamera() convenience method. The cameras API guide has been updated to reflect this new recommended way. Warning The strings used to identify cameras have changed in this release. As camera identifiers are generated by the Iristick Services, the change also applies to applications built with Iristick SDK 1.1 or earlier. There is no guarantee that identifiers remain stable across releases, devices or instances. Relying on stable identifiers, e.g., by hardcoding them or saving them in preferences, results in undefined behavior. Camera identifiers should always be treated as opaque strings that must be queried for every Headset instance with findCamera() or getCameraIdList() . New constants have been added as aliases to the MediaStore constants used as intent extras for the ACTION_IMAGE_CAPTURE and ACTION_VIDEO_CAPTURE intents. It is recommended to use the new constants: Intents.EXTRA_OUTPUT Intents.EXTRA_VIDEO_QUALITY Intents.EXTRA_SIZE_LIMIT Intents.EXTRA_DURATION_LIMIT The Iristick core and support libraries have been annotated with AndroidX annotations for a better developer experience in Android Studio. Firmware improvements \u00b6 This release contains a number of improvements to the device firmware. When running Iristick Services 1.2, the device firmware is updated automatically. The camera quality has been improved with better white balance in 5MP still captures, better auto-exposure results in low light conditions, and improved auto-focus algorithm. Frame timestamps provided through the SENSOR_TIMESTAMP capture result are now more accurate. Audio has also been improved with better speaker sound quality and higher microphone volume. Other changes \u00b6 The video capture intent ( ACTION_VIDEO_CAPTURE ) has a new codec selection algorithm which works across a wider range of smartphones. It will try to pick the common H.264/AVC codec if available. Recording low-quality videos will now correctly scale and crop the camera frames instead of capturing the top-left corner. The Iristick Services no longer prevent other applications from capturing the phone screen contents. While another application is capturing the screen, the display cloning to the heads-up display functionality is disabled. When the other application stops capturing the screen, the Iristick Services will request screen capture again and resume the display cloning functionality. The web console, available through the developer settings, has been rewritten to make display mirroring work on a broader range of browsers. The \"Disable Premium features\" developer setting has been removed as it was often misunderstood by users. Deprecation notices \u00b6 Relying on the Iristick Accessibility Service for UI interaction is now discouraged in production as it offers a suboptimal user experience. The accessibility service might be removed or become optional in a future release. As part of this move, the following methods of the IristickBinding class have been deprecated: setInteractionRules , along with the InteractionRule class, focusView , enterView . The camera2 support package has been deprecated. It is unmaintained and does not provide full access to all cameras functionality. Users are advised to follow the cameras API guide instead. The use of the EXTRA_SIZE_LIMIT extra for the ACTION_VIDEO_CAPTURE intent has been deprecated as it does not guarantee that the final size of the recorded video will not exceed the desired limit. The CaptureAdapter helper class has been deprecated in favor of the new CaptureListener2 abstract class. The timestamp argument of the CaptureListener.onCaptureStarted callback has been deprecated as it is now unrelated to the more accurate SENSOR_TIMESTAMP capture result. Users are advised to override the variant without timestamp argument from the CaptureListener2 abstract class instead. Patch releases since 1.2 \u00b6 Release 1.2.1 \u00b6 A regression that prevented manual camera gain to be set has been fixed. Firmware files for A08 hardware have been added. Release 1.2.2 \u00b6 The touchpad of new B08B hardware has been fixed. Release 1.2.3 \u00b6 Auto-focus on the B08B zoom camera has been fixed. Audio issues on some Samsung phones running Android 10 (e.g., XCover 4s) have been fixed. Release 1.2.4 \u00b6 Resolution 1280\u00d7960 has been added to the supported camera frame sizes. The sound quality of the internal speaker has been improved. The internal microphones are now used also when an earpiece is plugged in to improve the quality of recorded sound. The LED flashlight or laser pointer will not be re-enabled automatically anymore when disconnecting and reconnecting the headset without disconnecting the pocket unit. An issue preventing the phone display of some Android 10 devices to be dimmed when the pocket unit is in the pouch has been fixed. An issue preventing the screen recording permission dialog to be shown in some circumstances has been fixed. Support for obsolete B04, C04 and B05 hardware has been removed. Release 1.2.5 \u00b6 Voice command recognition performance has been improved. A regression yielding many false positives when using French voice commands has been fixed. Issues when using the cameras with low framerates or when zooming in have been fixed. An issue has been fixed that caused the camera intent to crash when the Iristick Services were not allowed to access the camera. Miscellaneous bugfixes. Release 1.2.6 \u00b6 Add support for Android 11. Release 1.2.7 \u00b6 The behavior of the camera intents and app have been improved when the headset is disconnected during video recording, or when the activity is put in background. Audio issues on Pixel 4a phones when booting the phone with the pocket unit attached, have been fixed. Miscellaneous bugfixes.", "title": "Release 1.2"}, {"location": "release-notes/1.2.html#whats-new-in-iristick-sdk-12", "text": "This is a minor feature release that is backward-compatible with previous 1.x releases. Applications built with SDK 1.0 up to 1.1 will continue to work with Iristick Services 1.2 without recompiling. Applications built with SDK 1.2 however require Iristick Services 1.2 or later to be installed.", "title": "What's new in Iristick SDK 1.2"}, {"location": "release-notes/1.2.html#ios-sdk-preview", "text": "This release introduces the first preview of the Iristick SDK for iOS devices, allowing iOS applications to run on Iristick smart glasses. The preview SDK is available on request. Please get in touch with Iristick if you are interested.", "title": "iOS SDK Preview"}, {"location": "release-notes/1.2.html#android-10-support", "text": "This release adds support for phones running on Android 10. Please note that, due to a bug in Android 10, your pocket unit's firmware may need to be upgraded before it can be used on Android 10. To do so, connect your pocket unit to a phone running on Android 9 or older with Iristick Services 1.2 installed. Android 10 has removed the option to grant screen capture permission to an app without asking every time. To allow smooth operation when headsets get connected and disconnected, the Iristick Services will now request screen capture permission as soon as a pocket unit is connected to the phone.", "title": "Android 10 support"}, {"location": "release-notes/1.2.html#barcode-scanning-api", "text": "In previous releases, barcode scanning was only available through the ACTION_SCAN_BARCODE intent. This release extends the camera API to give developers complete control over the barcode scanning process. The new API can be leveraged to provide continuous barcode scanning and even to scan multiple barcodes at once. The following keys have been added to the camera API: CameraCharacteristics.POSTPROCESS_MAXIMUM_BARCODE_COUNT CameraCharacteristics.POSTPROCESS_AVAILABLE_BARCODE_FORMATS CaptureRequest.POSTPROCESS_MODE CaptureRequest.POSTPROCESS_BARCODE_COUNT CaptureRequest.POSTPROCESS_BARCODE_FORMATS CaptureRequest.POSTPROCESS_BARCODE_TARGET CaptureRequest.POSTPROCESS_BARCODE_TARGET_TOLERANCE CaptureResult.POSTPROCESS_BARCODES Read the new barcode scanning API guide for more information.", "title": "Barcode scanning API"}, {"location": "release-notes/1.2.html#other-api-changes", "text": "The white balance of the cameras can now be controlled manually. The final white balance gains applied to a frame are also reported as part of the capture results. The corresponding new keys in the camera API are: CameraCharacteristics.CONTROL_AWB_AVAILABLE_MODES CaptureRequest.CONTROL_AWB_MODE CaptureRequest.COLOR_CORRECTION_GAIN_BLUE CaptureRequest.COLOR_CORRECTION_GAIN_RED CaptureResult.COLOR_CORRECTION_GAIN_BLUE CaptureResult.COLOR_CORRECTION_GAIN_RED To make it easier to select an Iristick camera, the Headset class got a new findCamera() convenience method. The cameras API guide has been updated to reflect this new recommended way. Warning The strings used to identify cameras have changed in this release. As camera identifiers are generated by the Iristick Services, the change also applies to applications built with Iristick SDK 1.1 or earlier. There is no guarantee that identifiers remain stable across releases, devices or instances. Relying on stable identifiers, e.g., by hardcoding them or saving them in preferences, results in undefined behavior. Camera identifiers should always be treated as opaque strings that must be queried for every Headset instance with findCamera() or getCameraIdList() . New constants have been added as aliases to the MediaStore constants used as intent extras for the ACTION_IMAGE_CAPTURE and ACTION_VIDEO_CAPTURE intents. It is recommended to use the new constants: Intents.EXTRA_OUTPUT Intents.EXTRA_VIDEO_QUALITY Intents.EXTRA_SIZE_LIMIT Intents.EXTRA_DURATION_LIMIT The Iristick core and support libraries have been annotated with AndroidX annotations for a better developer experience in Android Studio.", "title": "Other API changes"}, {"location": "release-notes/1.2.html#firmware-improvements", "text": "This release contains a number of improvements to the device firmware. When running Iristick Services 1.2, the device firmware is updated automatically. The camera quality has been improved with better white balance in 5MP still captures, better auto-exposure results in low light conditions, and improved auto-focus algorithm. Frame timestamps provided through the SENSOR_TIMESTAMP capture result are now more accurate. Audio has also been improved with better speaker sound quality and higher microphone volume.", "title": "Firmware improvements"}, {"location": "release-notes/1.2.html#other-changes", "text": "The video capture intent ( ACTION_VIDEO_CAPTURE ) has a new codec selection algorithm which works across a wider range of smartphones. It will try to pick the common H.264/AVC codec if available. Recording low-quality videos will now correctly scale and crop the camera frames instead of capturing the top-left corner. The Iristick Services no longer prevent other applications from capturing the phone screen contents. While another application is capturing the screen, the display cloning to the heads-up display functionality is disabled. When the other application stops capturing the screen, the Iristick Services will request screen capture again and resume the display cloning functionality. The web console, available through the developer settings, has been rewritten to make display mirroring work on a broader range of browsers. The \"Disable Premium features\" developer setting has been removed as it was often misunderstood by users.", "title": "Other changes"}, {"location": "release-notes/1.2.html#deprecation-notices", "text": "Relying on the Iristick Accessibility Service for UI interaction is now discouraged in production as it offers a suboptimal user experience. The accessibility service might be removed or become optional in a future release. As part of this move, the following methods of the IristickBinding class have been deprecated: setInteractionRules , along with the InteractionRule class, focusView , enterView . The camera2 support package has been deprecated. It is unmaintained and does not provide full access to all cameras functionality. Users are advised to follow the cameras API guide instead. The use of the EXTRA_SIZE_LIMIT extra for the ACTION_VIDEO_CAPTURE intent has been deprecated as it does not guarantee that the final size of the recorded video will not exceed the desired limit. The CaptureAdapter helper class has been deprecated in favor of the new CaptureListener2 abstract class. The timestamp argument of the CaptureListener.onCaptureStarted callback has been deprecated as it is now unrelated to the more accurate SENSOR_TIMESTAMP capture result. Users are advised to override the variant without timestamp argument from the CaptureListener2 abstract class instead.", "title": "Deprecation notices"}, {"location": "release-notes/1.2.html#patch-releases-since-12", "text": "", "title": "Patch releases since 1.2"}, {"location": "release-notes/1.2.html#release-121", "text": "A regression that prevented manual camera gain to be set has been fixed. Firmware files for A08 hardware have been added.", "title": "Release 1.2.1"}, {"location": "release-notes/1.2.html#release-122", "text": "The touchpad of new B08B hardware has been fixed.", "title": "Release 1.2.2"}, {"location": "release-notes/1.2.html#release-123", "text": "Auto-focus on the B08B zoom camera has been fixed. Audio issues on some Samsung phones running Android 10 (e.g., XCover 4s) have been fixed.", "title": "Release 1.2.3"}, {"location": "release-notes/1.2.html#release-124", "text": "Resolution 1280\u00d7960 has been added to the supported camera frame sizes. The sound quality of the internal speaker has been improved. The internal microphones are now used also when an earpiece is plugged in to improve the quality of recorded sound. The LED flashlight or laser pointer will not be re-enabled automatically anymore when disconnecting and reconnecting the headset without disconnecting the pocket unit. An issue preventing the phone display of some Android 10 devices to be dimmed when the pocket unit is in the pouch has been fixed. An issue preventing the screen recording permission dialog to be shown in some circumstances has been fixed. Support for obsolete B04, C04 and B05 hardware has been removed.", "title": "Release 1.2.4"}, {"location": "release-notes/1.2.html#release-125", "text": "Voice command recognition performance has been improved. A regression yielding many false positives when using French voice commands has been fixed. Issues when using the cameras with low framerates or when zooming in have been fixed. An issue has been fixed that caused the camera intent to crash when the Iristick Services were not allowed to access the camera. Miscellaneous bugfixes.", "title": "Release 1.2.5"}, {"location": "release-notes/1.2.html#release-126", "text": "Add support for Android 11.", "title": "Release 1.2.6"}, {"location": "release-notes/1.2.html#release-127", "text": "The behavior of the camera intents and app have been improved when the headset is disconnected during video recording, or when the activity is put in background. Audio issues on Pixel 4a phones when booting the phone with the pocket unit attached, have been fixed. Miscellaneous bugfixes.", "title": "Release 1.2.7"}, {"location": "release-notes/1.3.html", "text": "What's new in Iristick SDK 1.3 \u00b6 This is a feature release that is backward-compatible with previous 1.x releases. Applications built with SDK 1.0 up to 1.2 will continue to work with Iristick Services 1.3 without recompiling. Applications built with SDK 1.3 however require Iristick Services 1.3 or later to be installed. Iristick.H1 support \u00b6 This release adds support for the Iristick.H1 model. Most existing apps should not require any changes to support the new model. The rest of this section describes to the new features of the Iristick.H1 that might impact your app. Reversible device \u00b6 The Iristick.H1 can be used by both right and left eye dominant users by flipping it upside down. The rotation of display and camera frames according to the orientation of the device is taken care of by the SDK. When the device is flipped while connected, this will appear to the applications as if the headset has been disconnected and reconnected again. In order to support both orientations, the Iristick.H1 comes with two central cameras, one looking slightly downwards and one looking slightly upwards. Currently, only the downwards-looking camera can be accessed by applications. Portrait orientation of central cameras \u00b6 To increase the vertical field of view, the central cameras are mounted in portrait orientation. The resulting frames are cropped to the desired landscape resolution. By setting the SCALER_OFFSET key in capture requests, applications can digitally move the capture window up (with a negative vertical offset) or down (with a positive vertical offset). If the key is not set, the Default camera inclination setting of Iristick Services will be used. Higher resolution display \u00b6 The Iristick.H1 comes with a 2.5\u00d7 higher resolution display than the previous generation, while keeping the same aspect ratio. Application user interfaces that are not resolution-independent may need to be adapted. Iristick.G2 support \u00b6 This release adds support for the Iristick.G2 model. The G2 shares most characteristics of its predecessor, the Iristick.G1. The most notable change is the inclusion of improved central camera sensors that are mounted in portrait orientation, as for the Iristick.H1. See the discussion above for the potential impact for applications. Advanced voice commands \u00b6 The API for registering custom voice commands has been overhauled in this release. In addition to simple lists of commands, complex grammars can now be created to recognize different user inputs, such as numbers, dates, etc. See the documentation of the VoiceGrammar class for details on how to build complex grammars. The Headset.startVoice and Headset.stopVoice methods can then be used to start or stop listening for commands matching the grammar. Building on top of VoiceGrammar , the new VoiceCommandDispatcher class provides a convenient way to register a simple list of voice commands with callbacks attached to each command. Using VoiceCommandDispatcher is now the recommended way of registering simple voice commands. The examples code has been updated accordingly. Color preview during barcode scanning \u00b6 When scanning for barcodes, using the BARCODE capture request template, the captured frames will now show up in full color instead of being converted to grayscale. Deprecation notices \u00b6 The Headset.registerVoiceCommands and Headset.unregisterVoiceCommands methods have been deprecated in favor of the more convenient VoiceCommandDispatcher class. The FORMAT capture request key has been deprecated. The required pixel format should be provided when creating the ImageReader output instead. Patch releases since 1.3 \u00b6 Release 1.3.1 \u00b6 Preliminary support for Android 12. Improved audio quality on G1 and G2 headsets by removing speaker over-amplification. Fixed initial orientation detection of H1 headsets. Fixed wrong auto-exposure in 1080p mode under some lighting conditions. Fixed auto-white balance of the center camera on G2 headsets. Fixed still captures on G2 and H1 center cameras. Fixed occasional purple banding artefacts on G2 and H1 center cameras. Added firmware for H07 hardware. Restored support for old B06 hardware. Release 1.3.2 \u00b6 Improved audio on H1 headsets. Improved image quality on the center cameras of G2 and H1 headsets. The examples app now enable scanning PDF417 and Aztec barcodes. Miscellaneous bugfixes.", "title": "Release 1.3"}, {"location": "release-notes/1.3.html#whats-new-in-iristick-sdk-13", "text": "This is a feature release that is backward-compatible with previous 1.x releases. Applications built with SDK 1.0 up to 1.2 will continue to work with Iristick Services 1.3 without recompiling. Applications built with SDK 1.3 however require Iristick Services 1.3 or later to be installed.", "title": "What's new in Iristick SDK 1.3"}, {"location": "release-notes/1.3.html#iristickh1-support", "text": "This release adds support for the Iristick.H1 model. Most existing apps should not require any changes to support the new model. The rest of this section describes to the new features of the Iristick.H1 that might impact your app.", "title": "Iristick.H1 support"}, {"location": "release-notes/1.3.html#reversible-device", "text": "The Iristick.H1 can be used by both right and left eye dominant users by flipping it upside down. The rotation of display and camera frames according to the orientation of the device is taken care of by the SDK. When the device is flipped while connected, this will appear to the applications as if the headset has been disconnected and reconnected again. In order to support both orientations, the Iristick.H1 comes with two central cameras, one looking slightly downwards and one looking slightly upwards. Currently, only the downwards-looking camera can be accessed by applications.", "title": "Reversible device"}, {"location": "release-notes/1.3.html#portrait-orientation-of-central-cameras", "text": "To increase the vertical field of view, the central cameras are mounted in portrait orientation. The resulting frames are cropped to the desired landscape resolution. By setting the SCALER_OFFSET key in capture requests, applications can digitally move the capture window up (with a negative vertical offset) or down (with a positive vertical offset). If the key is not set, the Default camera inclination setting of Iristick Services will be used.", "title": "Portrait orientation of central cameras"}, {"location": "release-notes/1.3.html#higher-resolution-display", "text": "The Iristick.H1 comes with a 2.5\u00d7 higher resolution display than the previous generation, while keeping the same aspect ratio. Application user interfaces that are not resolution-independent may need to be adapted.", "title": "Higher resolution display"}, {"location": "release-notes/1.3.html#iristickg2-support", "text": "This release adds support for the Iristick.G2 model. The G2 shares most characteristics of its predecessor, the Iristick.G1. The most notable change is the inclusion of improved central camera sensors that are mounted in portrait orientation, as for the Iristick.H1. See the discussion above for the potential impact for applications.", "title": "Iristick.G2 support"}, {"location": "release-notes/1.3.html#advanced-voice-commands", "text": "The API for registering custom voice commands has been overhauled in this release. In addition to simple lists of commands, complex grammars can now be created to recognize different user inputs, such as numbers, dates, etc. See the documentation of the VoiceGrammar class for details on how to build complex grammars. The Headset.startVoice and Headset.stopVoice methods can then be used to start or stop listening for commands matching the grammar. Building on top of VoiceGrammar , the new VoiceCommandDispatcher class provides a convenient way to register a simple list of voice commands with callbacks attached to each command. Using VoiceCommandDispatcher is now the recommended way of registering simple voice commands. The examples code has been updated accordingly.", "title": "Advanced voice commands"}, {"location": "release-notes/1.3.html#color-preview-during-barcode-scanning", "text": "When scanning for barcodes, using the BARCODE capture request template, the captured frames will now show up in full color instead of being converted to grayscale.", "title": "Color preview during barcode scanning"}, {"location": "release-notes/1.3.html#deprecation-notices", "text": "The Headset.registerVoiceCommands and Headset.unregisterVoiceCommands methods have been deprecated in favor of the more convenient VoiceCommandDispatcher class. The FORMAT capture request key has been deprecated. The required pixel format should be provided when creating the ImageReader output instead.", "title": "Deprecation notices"}, {"location": "release-notes/1.3.html#patch-releases-since-13", "text": "", "title": "Patch releases since 1.3"}, {"location": "release-notes/1.3.html#release-131", "text": "Preliminary support for Android 12. Improved audio quality on G1 and G2 headsets by removing speaker over-amplification. Fixed initial orientation detection of H1 headsets. Fixed wrong auto-exposure in 1080p mode under some lighting conditions. Fixed auto-white balance of the center camera on G2 headsets. Fixed still captures on G2 and H1 center cameras. Fixed occasional purple banding artefacts on G2 and H1 center cameras. Added firmware for H07 hardware. Restored support for old B06 hardware.", "title": "Release 1.3.1"}, {"location": "release-notes/1.3.html#release-132", "text": "Improved audio on H1 headsets. Improved image quality on the center cameras of G2 and H1 headsets. The examples app now enable scanning PDF417 and Aztec barcodes. Miscellaneous bugfixes.", "title": "Release 1.3.2"}, {"location": "reference/com/iristick/smartglass/core/camera/Barcode.html", "text": "com.iristick.smartglass.core.camera.Barcode", "title": "Barcode"}, {"location": "reference/com/iristick/smartglass/core/camera/CameraCharacteristics.html", "text": "com.iristick.smartglass.core.camera.CameraCharacteristics", "title": "CameraCharacteristics"}, {"location": "reference/com/iristick/smartglass/core/camera/CameraCharacteristics.Key.html", "text": "com.iristick.smartglass.core.camera.CameraCharacteristics.Key", "title": "CameraCharacteristics.Key"}, {"location": "reference/com/iristick/smartglass/core/camera/CameraCharacteristics.StreamConfigurationMap.html", "text": "com.iristick.smartglass.core.camera.CameraCharacteristics.StreamConfigurationMap", "title": "CameraCharacteristics.StreamConfigurationMap"}, {"location": "reference/com/iristick/smartglass/core/camera/CameraDevice.html", "text": "com.iristick.smartglass.core.camera.CameraDevice", "title": "CameraDevice"}, {"location": "reference/com/iristick/smartglass/core/camera/CameraDevice.Listener.html", "text": "com.iristick.smartglass.core.camera.CameraDevice.Listener", "title": "CameraDevice.Listener"}, {"location": "reference/com/iristick/smartglass/core/camera/CaptureAdapter.html", "text": "com.iristick.smartglass.core.camera.CaptureAdapter", "title": "CaptureAdapter"}, {"location": "reference/com/iristick/smartglass/core/camera/CaptureFailure.html", "text": "com.iristick.smartglass.core.camera.CaptureFailure", "title": "CaptureFailure"}, {"location": "reference/com/iristick/smartglass/core/camera/CaptureListener.html", "text": "com.iristick.smartglass.core.camera.CaptureListener", "title": "CaptureListener"}, {"location": "reference/com/iristick/smartglass/core/camera/CaptureListener2.html", "text": "com.iristick.smartglass.core.camera.CaptureListener2", "title": "CaptureListener2"}, {"location": "reference/com/iristick/smartglass/core/camera/CaptureRequest.html", "text": "com.iristick.smartglass.core.camera.CaptureRequest", "title": "CaptureRequest"}, {"location": "reference/com/iristick/smartglass/core/camera/CaptureRequest.Builder.html", "text": "com.iristick.smartglass.core.camera.CaptureRequest.Builder", "title": "CaptureRequest.Builder"}, {"location": "reference/com/iristick/smartglass/core/camera/CaptureRequest.Key.html", "text": "com.iristick.smartglass.core.camera.CaptureRequest.Key", "title": "CaptureRequest.Key"}, {"location": "reference/com/iristick/smartglass/core/camera/CaptureResult.html", "text": "com.iristick.smartglass.core.camera.CaptureResult", "title": "CaptureResult"}, {"location": "reference/com/iristick/smartglass/core/camera/CaptureResult.Key.html", "text": "com.iristick.smartglass.core.camera.CaptureResult.Key", "title": "CaptureResult.Key"}, {"location": "reference/com/iristick/smartglass/core/camera/CaptureSession.html", "text": "com.iristick.smartglass.core.camera.CaptureSession", "title": "CaptureSession"}, {"location": "reference/com/iristick/smartglass/core/camera/CaptureSession.Listener.html", "text": "com.iristick.smartglass.core.camera.CaptureSession.Listener", "title": "CaptureSession.Listener"}, {"location": "reference/com/iristick/smartglass/core/DisplayListener.html", "text": "com.iristick.smartglass.core.DisplayListener", "title": "DisplayListener"}, {"location": "reference/com/iristick/smartglass/core/Headset.html", "text": "com.iristick.smartglass.core.Headset", "title": "Headset"}, {"location": "reference/com/iristick/smartglass/core/Headset.InteractionModeListener.html", "text": "com.iristick.smartglass.core.Headset.InteractionModeListener", "title": "Headset.InteractionModeListener"}, {"location": "reference/com/iristick/smartglass/core/Intents.html", "text": "com.iristick.smartglass.core.Intents", "title": "Intents"}, {"location": "reference/com/iristick/smartglass/core/InteractionRule.html", "text": "com.iristick.smartglass.core.InteractionRule", "title": "InteractionRule"}, {"location": "reference/com/iristick/smartglass/core/InteractionRule.Key.html", "text": "com.iristick.smartglass.core.InteractionRule.Key", "title": "InteractionRule.Key"}, {"location": "reference/com/iristick/smartglass/core/IristickBinding.html", "text": "com.iristick.smartglass.core.IristickBinding", "title": "IristickBinding"}, {"location": "reference/com/iristick/smartglass/core/IristickConnection.html", "text": "com.iristick.smartglass.core.IristickConnection", "title": "IristickConnection"}, {"location": "reference/com/iristick/smartglass/core/IristickConnection2.html", "text": "com.iristick.smartglass.core.IristickConnection2", "title": "IristickConnection2"}, {"location": "reference/com/iristick/smartglass/core/IristickManager.html", "text": "com.iristick.smartglass.core.IristickManager", "title": "IristickManager"}, {"location": "reference/com/iristick/smartglass/core/PocketUnit.html", "text": "com.iristick.smartglass.core.PocketUnit", "title": "PocketUnit"}, {"location": "reference/com/iristick/smartglass/core/PocketUnit.BatteryCallback.html", "text": "com.iristick.smartglass.core.PocketUnit.BatteryCallback", "title": "PocketUnit.BatteryCallback"}, {"location": "reference/com/iristick/smartglass/core/Sensor.html", "text": "com.iristick.smartglass.core.Sensor", "title": "Sensor"}, {"location": "reference/com/iristick/smartglass/core/SensorEvent.html", "text": "com.iristick.smartglass.core.SensorEvent", "title": "SensorEvent"}, {"location": "reference/com/iristick/smartglass/core/SensorEventListener.html", "text": "com.iristick.smartglass.core.SensorEventListener", "title": "SensorEventListener"}, {"location": "reference/com/iristick/smartglass/core/TouchEvent.html", "text": "com.iristick.smartglass.core.TouchEvent", "title": "TouchEvent"}, {"location": "reference/com/iristick/smartglass/core/TouchEvent.Callback.html", "text": "com.iristick.smartglass.core.TouchEvent.Callback", "title": "TouchEvent.Callback"}, {"location": "reference/com/iristick/smartglass/core/VoiceCommandDispatcher.html", "text": "com.iristick.smartglass.core.VoiceCommandDispatcher", "title": "VoiceCommandDispatcher"}, {"location": "reference/com/iristick/smartglass/core/VoiceCommandDispatcher.Builder.html", "text": "com.iristick.smartglass.core.VoiceCommandDispatcher.Builder", "title": "VoiceCommandDispatcher.Builder"}, {"location": "reference/com/iristick/smartglass/core/VoiceEvent.html", "text": "com.iristick.smartglass.core.VoiceEvent", "title": "VoiceEvent"}, {"location": "reference/com/iristick/smartglass/core/VoiceEvent.Callback.html", "text": "com.iristick.smartglass.core.VoiceEvent.Callback", "title": "VoiceEvent.Callback"}, {"location": "reference/com/iristick/smartglass/core/VoiceGrammar.html", "text": "com.iristick.smartglass.core.VoiceGrammar", "title": "VoiceGrammar"}, {"location": "reference/com/iristick/smartglass/core/VoiceGrammar.Builder.html", "text": "com.iristick.smartglass.core.VoiceGrammar.Builder", "title": "VoiceGrammar.Builder"}, {"location": "reference/com/iristick/smartglass/support/app/HudActivity.html", "text": "com.iristick.smartglass.support.app.HudActivity", "title": "HudActivity"}, {"location": "reference/com/iristick/smartglass/support/app/HudPresentation.html", "text": "com.iristick.smartglass.support.app.HudPresentation", "title": "HudPresentation"}, {"location": "reference/com/iristick/smartglass/support/app/IristickApp.html", "text": "com.iristick.smartglass.support.app.IristickApp", "title": "IristickApp"}, {"location": "reference/com/iristick/smartglass/support/app/IristickConfiguration.html", "text": "com.iristick.smartglass.support.app.IristickConfiguration", "title": "IristickConfiguration"}, {"location": "reference/com/iristick/smartglass/support/camera2/params/BlackLevelPattern.html", "text": "com.iristick.smartglass.support.camera2.params.BlackLevelPattern", "title": "BlackLevelPattern"}, {"location": "reference/com/iristick/smartglass/support/camera2/params/ColorSpaceTransform.html", "text": "com.iristick.smartglass.support.camera2.params.ColorSpaceTransform", "title": "ColorSpaceTransform"}, {"location": "reference/com/iristick/smartglass/support/camera2/params/Face.html", "text": "com.iristick.smartglass.support.camera2.params.Face", "title": "Face"}, {"location": "reference/com/iristick/smartglass/support/camera2/params/InputConfiguration.html", "text": "com.iristick.smartglass.support.camera2.params.InputConfiguration", "title": "InputConfiguration"}, {"location": "reference/com/iristick/smartglass/support/camera2/params/LensShadingMap.html", "text": "com.iristick.smartglass.support.camera2.params.LensShadingMap", "title": "LensShadingMap"}, {"location": "reference/com/iristick/smartglass/support/camera2/params/MeteringRectangle.html", "text": "com.iristick.smartglass.support.camera2.params.MeteringRectangle", "title": "MeteringRectangle"}, {"location": "reference/com/iristick/smartglass/support/camera2/params/OutputConfiguration.html", "text": "com.iristick.smartglass.support.camera2.params.OutputConfiguration", "title": "OutputConfiguration"}, {"location": "reference/com/iristick/smartglass/support/camera2/params/RggbChannelVector.html", "text": "com.iristick.smartglass.support.camera2.params.RggbChannelVector", "title": "RggbChannelVector"}, {"location": "reference/com/iristick/smartglass/support/camera2/params/StreamConfigurationMap.html", "text": "com.iristick.smartglass.support.camera2.params.StreamConfigurationMap", "title": "StreamConfigurationMap"}, {"location": "reference/com/iristick/smartglass/support/camera2/params/TonemapCurve.html", "text": "com.iristick.smartglass.support.camera2.params.TonemapCurve", "title": "TonemapCurve"}, {"location": "reference/com/iristick/smartglass/support/camera2/CameraAccessException.html", "text": "com.iristick.smartglass.support.camera2.CameraAccessException", "title": "CameraAccessException"}, {"location": "reference/com/iristick/smartglass/support/camera2/CameraCaptureSession.html", "text": "com.iristick.smartglass.support.camera2.CameraCaptureSession", "title": "CameraCaptureSession"}, {"location": "reference/com/iristick/smartglass/support/camera2/CameraCaptureSession.CaptureCallback.html", "text": "com.iristick.smartglass.support.camera2.CameraCaptureSession.CaptureCallback", "title": "CameraCaptureSession.CaptureCallback"}, {"location": "reference/com/iristick/smartglass/support/camera2/CameraCaptureSession.StateCallback.html", "text": "com.iristick.smartglass.support.camera2.CameraCaptureSession.StateCallback", "title": "CameraCaptureSession.StateCallback"}, {"location": "reference/com/iristick/smartglass/support/camera2/CameraCharacteristics.html", "text": "com.iristick.smartglass.support.camera2.CameraCharacteristics", "title": "CameraCharacteristics"}, {"location": "reference/com/iristick/smartglass/support/camera2/CameraCharacteristics.Key.html", "text": "com.iristick.smartglass.support.camera2.CameraCharacteristics.Key", "title": "CameraCharacteristics.Key"}, {"location": "reference/com/iristick/smartglass/support/camera2/CameraConstrainedHighSpeedCaptureSession.html", "text": "com.iristick.smartglass.support.camera2.CameraConstrainedHighSpeedCaptureSession", "title": "CameraConstrainedHighSpeedCaptureSession"}, {"location": "reference/com/iristick/smartglass/support/camera2/CameraDevice.html", "text": "com.iristick.smartglass.support.camera2.CameraDevice", "title": "CameraDevice"}, {"location": "reference/com/iristick/smartglass/support/camera2/CameraDevice.StateCallback.html", "text": "com.iristick.smartglass.support.camera2.CameraDevice.StateCallback", "title": "CameraDevice.StateCallback"}, {"location": "reference/com/iristick/smartglass/support/camera2/CameraFormat.html", "text": "com.iristick.smartglass.support.camera2.CameraFormat", "title": "CameraFormat"}, {"location": "reference/com/iristick/smartglass/support/camera2/CameraManager.html", "text": "com.iristick.smartglass.support.camera2.CameraManager", "title": "CameraManager"}, {"location": "reference/com/iristick/smartglass/support/camera2/CameraManager.AvailabilityCallback.html", "text": "com.iristick.smartglass.support.camera2.CameraManager.AvailabilityCallback", "title": "CameraManager.AvailabilityCallback"}, {"location": "reference/com/iristick/smartglass/support/camera2/CameraManager.HeadsetCallback.html", "text": "com.iristick.smartglass.support.camera2.CameraManager.HeadsetCallback", "title": "CameraManager.HeadsetCallback"}, {"location": "reference/com/iristick/smartglass/support/camera2/CameraManager.TorchCallback.html", "text": "com.iristick.smartglass.support.camera2.CameraManager.TorchCallback", "title": "CameraManager.TorchCallback"}, {"location": "reference/com/iristick/smartglass/support/camera2/CameraMetadata.html", "text": "com.iristick.smartglass.support.camera2.CameraMetadata", "title": "CameraMetadata"}, {"location": "reference/com/iristick/smartglass/support/camera2/CaptureFailure.html", "text": "com.iristick.smartglass.support.camera2.CaptureFailure", "title": "CaptureFailure"}, {"location": "reference/com/iristick/smartglass/support/camera2/CaptureRequest.html", "text": "com.iristick.smartglass.support.camera2.CaptureRequest", "title": "CaptureRequest"}, {"location": "reference/com/iristick/smartglass/support/camera2/CaptureRequest.Builder.html", "text": "com.iristick.smartglass.support.camera2.CaptureRequest.Builder", "title": "CaptureRequest.Builder"}, {"location": "reference/com/iristick/smartglass/support/camera2/CaptureRequest.Key.html", "text": "com.iristick.smartglass.support.camera2.CaptureRequest.Key", "title": "CaptureRequest.Key"}, {"location": "reference/com/iristick/smartglass/support/camera2/CaptureResult.html", "text": "com.iristick.smartglass.support.camera2.CaptureResult", "title": "CaptureResult"}, {"location": "reference/com/iristick/smartglass/support/camera2/CaptureResult.Key.html", "text": "com.iristick.smartglass.support.camera2.CaptureResult.Key", "title": "CaptureResult.Key"}, {"location": "reference/com/iristick/smartglass/support/camera2/DngCreator.html", "text": "com.iristick.smartglass.support.camera2.DngCreator", "title": "DngCreator"}, {"location": "reference/com/iristick/smartglass/support/camera2/TotalCaptureResult.html", "text": "com.iristick.smartglass.support.camera2.TotalCaptureResult", "title": "TotalCaptureResult"}]}; var search = { index: new Promise(resolve => setTimeout(() => resolve(local_index), 0)) }